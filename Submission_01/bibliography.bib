@article{almaatooq2024beyond, title={Beyond playing 20 questions with nature: Integrative experiment design in the social and behavioral sciences}, volume={47}, DOI={10.1017/S0140525X22002874}, journal={Behavioral and Brain Sciences}, author={Almaatouq, Abdullah and Griffiths, Thomas L. and Suchow, Jordan W. and Whiting, Mark E. and Evans, James and Watts, Duncan J.}, year={2024}}

@article{henderson2016bayesian,
  title={Bayesian analysis of heterogeneous treatment effects for patient-centered outcomes research},
  author={Henderson, Nicholas C and Louis, Thomas A and Wang, Chenguang and Varadhan, Ravi},
  journal={Health Services and Outcomes Research Methodology},
  volume={16},
  pages={213--233},
  year={2016},
  publisher={Springer}
}

@article{alvero2024large,
  title={Large Language Models, Social Demography, and Hegemony: Comparing Authorship in Human and Synthetic Text},
  author={Alvero, AJ and Lee, Jinsook and Regla-Vargas, Alejandra and Kizilec, Rene and Joachims, Thorsten and Antonio, Anthony Lising},
  year={2024}
}

@incollection{friedman_methodology_1953,
	title = {The {Methodology} of {Positive} {Economics}},
	booktitle = {Essays in {Positive} {Economics}},
	publisher = {University of Chicago Press},
	author = {Friedman, Milton},
	year = {1953},
	pages = {3--43},
	file = {Friedman 1953 Methodology of Pos Ec.pdf:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/GIDV9KTM/Friedman 1953 Methodology of Pos Ec.pdf:application/pdf;friedmanMethodologyPositiveEconomics1953-zotero.md:C\:\\Users\\david\\OneDrive - Zeppelin-University gGmbH\\Documents\\Zotero\\batch_export\\friedmanMethodologyPositiveEconomics1953-zotero.md:text/plain},
}
@article{tappin_quantifying_2023,
	title = {Quantifying the potential persuasive returns to political microtargeting},
	volume = {120},
	url = {https://www.pnas.org/doi/10.1073/pnas.2216261120},
	doi = {10.1073/pnas.2216261120},
	abstract = {Much concern has been raised about the power of political microtargeting to sway voters’ opinions, influence elections, and undermine democracy. Yet little research has directly estimated the persuasive advantage of microtargeting over alternative campaign strategies. Here, we do so using two studies focused on U.S. policy issue advertising. To implement a microtargeting strategy, we combined machine learning with message pretesting to determine which advertisements to show to which individuals to maximize persuasive impact. Using survey experiments, we then compared the performance of this microtargeting strategy against two other messaging strategies. Overall, we estimate that our microtargeting strategy outperformed these strategies by an average of 70\% or more in a context where all of the messages aimed to influence the same policy attitude (Study 1). Notably, however, we found no evidence that targeting messages by more than one covariate yielded additional persuasive gains, and the performance advantage of microtargeting was primarily visible for one of the two policy issues under study. Moreover, when microtargeting was used instead to identify which policy attitudes to target with messaging (Study 2), its advantage was more limited. Taken together, these results suggest that the use of microtargeting—combining message pretesting with machine learning—can potentially increase campaigns’ persuasive influence and may not require the collection of vast amounts of personal data to uncover complex interactions between audience characteristics and political messaging. However, the extent to which this approach confers a persuasive advantage over alternative strategies likely depends heavily on context.},
	number = {25},
	urldate = {2024-08-08},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Tappin, Ben M. and Wittenberg, Chloe and Hewitt, Luke B. and Berinsky, Adam J. and Rand, David G.},
	month = jun,
	year = {2023},
	note = {Publisher: Proceedings of the National Academy of Sciences},
}

@article{meng_statistical_2018,
	title = {Statistical paradises and paradoxes in big data ({I}): {Law} of large populations, big data paradox, and the 2016 {US} presidential election},
	volume = {12},
	issn = {1932-6157, 1941-7330},
	shorttitle = {Statistical paradises and paradoxes in big data ({I})},
	url = {https://projecteuclid.org/journals/annals-of-applied-statistics/volume-12/issue-2/Statistical-paradises-and-paradoxes-in-big-data-I--Law/10.1214/18-AOAS1161SF.full},
	doi = {10.1214/18-AOAS1161SF},
	abstract = {Statisticians are increasingly posed with thought-provoking and even paradoxical questions, challenging our qualifications for entering the statistical paradises created by Big Data. By developing measures for data quality, this article suggests a framework to address such a question: “Which one should I trust more: a 1\% survey with 60\% response rate or a self-reported administrative dataset covering 80\% of the population?” A 5-element Euler-formula-like identity shows that for any dataset of size \$n\$, probabilistic or not, the difference between the sample average \${\textbackslash}overline\{X\}\_\{n\}\$ and the population average \${\textbackslash}overline\{X\}\_\{N\}\$ is the product of three terms: (1) a data quality measure, \${\textbackslash}rho\_\{\{R,X\}\}\$, the correlation between \$X\_\{j\}\$ and the response/recording indicator \$R\_\{j\}\$; (2) a data quantity measure, \${\textbackslash}sqrt\{(N-n)/n\}\$, where \$N\$ is the population size; and (3) a problem difficulty measure, \${\textbackslash}sigma\_\{X\}\$, the standard deviation of \$X\$. This decomposition provides multiple insights: (I) Probabilistic sampling ensures high data quality by controlling \${\textbackslash}rho\_\{\{R,X\}\}\$ at the level of \$N{\textasciicircum}\{-1/2\}\$; (II) When we lose this control, the impact of \$N\$ is no longer canceled by \${\textbackslash}rho\_\{\{R,X\}\}\$, leading to a Law of Large Populations (LLP), that is, our estimation error, relative to the benchmarking rate \$1/{\textbackslash}sqrt\{n\}\$, increases with \${\textbackslash}sqrt\{N\}\$; and (III) the “bigness” of such Big Data (for population inferences) should be measured by the relative size \$f=n/N\$, not the absolute size \$n\$; (IV) When combining data sources for population inferences, those relatively tiny but higher quality ones should be given far more weights than suggested by their sizes. Estimates obtained from the Cooperative Congressional Election Study (CCES) of the 2016 US presidential election suggest a \${\textbackslash}rho\_\{\{R,X\}\}{\textbackslash}approx-0.005\$ for self-reporting to vote for Donald Trump. Because of LLP, this seemingly minuscule data defect correlation implies that the simple sample proportion of the self-reported voting preference for Trump from \$1{\textbackslash}\%\$ of the US eligible voters, that is, \$n{\textbackslash}approx2{\textbackslash}mbox\{,\}300{\textbackslash}mbox\{,\}000\$, has the same mean squared error as the corresponding sample proportion from a genuine simple random sample of size \$n{\textbackslash}approx400\$, a \$99.98{\textbackslash}\%\$ reduction of sample size (and hence our confidence). The CCES data demonstrate LLP vividly: on average, the larger the state’s voter populations, the further away the actual Trump vote shares from the usual \$95{\textbackslash}\%\$ confidence intervals based on the sample proportions. This should remind us that, without taking data quality into account, population inferences with Big Data are subject to a Big Data Paradox: the more the data, the surer we fool ourselves.},
	number = {2},
	urldate = {2024-08-09},
	journal = {The Annals of Applied Statistics},
	author = {Meng, Xiao-Li},
	month = jun,
	year = {2018},
	keywords = {Bias-variance tradeoff, data confidentiality and privacy, data defect correlation, data defect index (d.d.i.), data quality-quantity tradeoff, Euler identity, Monte Carlo and Quasi Monte Carlo (MCQMC), non-response bias},
	pages = {685--726},
}
@article{
mei2024turing,
author = {Qiaozhu Mei  and Yutong Xie  and Walter Yuan  and Matthew O. Jackson },
title = {A Turing test of whether AI chatbots are behaviorally similar to humans},
journal = {Proceedings of the National Academy of Sciences},
volume = {121},
number = {9},
year = {2024},
doi = {10.1073/pnas.2313925121},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2313925121},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2313925121},
abstract = {We administer a Turing test to AI chatbots. We examine how chatbots behave in a suite of classic behavioral games that are designed to elicit characteristics such as trust, fairness, risk-aversion, cooperation, etc., as well as how they respond to a traditional Big-5 psychological survey that measures personality traits. ChatGPT-4 exhibits behavioral and personality traits that are statistically indistinguishable from a random human from tens of thousands of human subjects from more than 50 countries. Chatbots also modify their behavior based on previous experience and contexts “as if” they were learning from the interactions and change their behavior in response to different framings of the same strategic situation. Their behaviors are often distinct from average and modal human behaviors, in which case they tend to behave on the more altruistic and cooperative end of the distribution. We estimate that they act as if they are maximizing an average of their own and partner’s payoffs.}}


@article{bail_can_2024,
	title = {Can {Generative} {AI} improve social science?},
	volume = {121},
	url = {https://www.pnas.org/doi/full/10.1073/pnas.2314021121},
	doi = {10.1073/pnas.2314021121},
	abstract = {Generative AI that can produce realistic text, images, and other human-like outputs is currently transforming many different industries. Yet it is not yet known how such tools might influence social science research. I argue Generative AI has the potential to improve survey research, online experiments, automated content analyses, agent-based models, and other techniques commonly used to study human behavior. In the second section of this article, I discuss the many limitations of Generative AI. I examine how bias in the data used to train these tools can negatively impact social science research—as well as a range of other challenges related to ethics, replication, environmental impact, and the proliferation of low-quality research. I conclude by arguing that social scientists can address many of these limitations by creating open-source infrastructure for research on human behavior. Such infrastructure is not only necessary to ensure broad access to high-quality research tools, I argue, but also because the progress of AI will require deeper understanding of the social forces that guide human behavior.},
	number = {21},
	urldate = {2024-08-09},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Bail, Christopher A.},
	month = may,
	year = {2024},
}

@misc{angelopoulos2024ppi,
      title={PPI++: Efficient Prediction-Powered Inference}, 
      author={Anastasios N. Angelopoulos and John C. Duchi and Tijana Zrnic},
      year={2024},
      eprint={2311.01453},
      archivePrefix={arXiv},
      primaryClass={stat.ML}
}

@article{jones2011bayesian,
  title={Bayesian models for subgroup analysis in clinical trials},
  author={Jones, Hayley E and Ohlssen, David I and Neuenschwander, Beat and Racine, Amy and Branson, Michael},
  journal={Clinical Trials},
  volume={8},
  number={2},
  pages={129--143},
  year={2011},
  publisher={SAGE Publications UK}
}

@article{tibshirani1996regression,
  title={Regression shrinkage and selection via the lasso},
  author={Tibshirani, Robert},
  journal={Journal of the Royal Statistical Society Series B: Statistical Methodology},
  volume={58},
  number={1},
  pages={267--288},
  year={1996},
  publisher={Oxford University Press}
}

@article{angelopoulos_prediction-powered_2023-1,
	title = {Prediction-powered inference},
	volume = {382},
	url = {https://www.science.org/doi/full/10.1126/science.adi6000},
	doi = {10.1126/science.adi6000},
	abstract = {Prediction-powered inference is a framework for performing valid statistical inference when an experimental dataset is supplemented with predictions from a machine-learning system. The framework yields simple algorithms for computing provably valid confidence intervals for quantities such as means, quantiles, and linear and logistic regression coefficients without making any assumptions about the machine-learning algorithm that supplies the predictions. Furthermore, more accurate predictions translate to smaller confidence intervals. Prediction-powered inference could enable researchers to draw valid and more data-efficient conclusions using machine learning. The benefits of prediction-powered inference were demonstrated with datasets from proteomics, astronomy, genomics, remote sensing, census analysis, and ecology.},
	number = {6671},
	urldate = {2024-01-28},
	journal = {Science},
	author = {Angelopoulos, Anastasios N. and Bates, Stephen and Fannjiang, Clara and Jordan, Michael I. and Zrnic, Tijana},
	month = nov,
	year = {2023},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {669--674},
}

@article{takemoto_moral_2024,
	title = {The moral machine experiment on large language models},
	volume = {11},
	url = {https://royalsocietypublishing.org/doi/10.1098/rsos.231393},
	doi = {10.1098/rsos.231393},
	abstract = {As large language models (LLMs) have become more deeply integrated into various sectors, understanding how they make moral judgements has become crucial, particularly in the realm of autonomous driving. This study used the moral machine framework to investigate the ethical decision-making tendencies of prominent LLMs, including GPT-3.5, GPT-4, PaLM 2 and Llama 2, to compare their responses with human preferences. While LLMs' and humans' preferences such as prioritizing humans over pets and favouring saving more lives are broadly aligned, PaLM 2 and Llama 2, especially, evidence distinct deviations. Additionally, despite the qualitative similarities between the LLM and human preferences, there are significant quantitative disparities, suggesting that LLMs might lean toward more uncompromising decisions, compared with the milder inclinations of humans. These insights elucidate the ethical frameworks of LLMs and their potential implications for autonomous driving.},
	number = {2},
	urldate = {2024-04-20},
	journal = {Royal Society Open Science},
	author = {Takemoto, Kazuhiro},
	month = feb,
	year = {2024},
	keywords = {ChatGPT, large language models, autonomous driving, moral machine},
	pages = {231393},
	file = {Full Text PDF:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/TRRSIZZX/Takemoto - 2024 - The moral machine experiment on large language mod.pdf:application/pdf},
}

@article{lazer2009css,
	title = {Computational {Social} {Science}},
	volume = {323},
	issn = {0036-8075, 1095-9203},
	shorttitle = {{SOCIAL} {SCIENCE}},
	url = {https://www.sciencemag.org/lookup/doi/10.1126/science.1167742},
	doi = {10.1126/science.1167742},
	language = {en},
	number = {5915},
	urldate = {2020-12-09},
	journal = {Science},
	author = {Lazer, D. and Pentland, A. and Adamic, L. and Aral, S. and Barabasi, A.-L. and Brewer, D. and Christakis, N. and Contractor, N. and Fowler, J. and Gutmann, M. and Jebara, T. and King, G. and Macy, M. and Roy, D. and Van Alstyne, M.},
	month = feb,
	year = {2009},
	pages = {721--723},
	file = {Lazer et al. - 2009 - SOCIAL SCIENCE Computational Social Science.pdf:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/YAFYSM5P/Lazer et al. - 2009 - SOCIAL SCIENCE Computational Social Science.pdf:application/pdf;lazer2009css - Extracted Annotations (172021, 105450 AM)What value might a computational social science—based in an open academic .md:C\:\\Users\\david\\Desktop\\lazer2009css - Extracted Annotations (172021, 105450 AM)What value might a computational social science—based in an open academic .md:text/plain},
}
@book{cohen_statistical_1988,
	address = {Hillsdale, N.J.},
	edition = {2nd},
	title = {Statistical Power Analysis for the Behavioral Sciences},
	isbn = {978-0-8058-0283-2},
	language = {en},
	publisher = {L. Erlbaum Associates},
	author = {Cohen, Jacob},
	year = {1988},
	keywords = {Social sciences, Statistical methods, Probabilities, Statistical power analysis}
}
@article{stadtfeld_statistical_2020,
	title = {Statistical {Power} in {Longitudinal} {Network} {Studies}},
	volume = {49},
	issn = {0049-1241},
	url = {https://doi.org/10.1177/0049124118769113},
	doi = {10.1177/0049124118769113},
	abstract = {Longitudinal social network studies can easily suffer from insufficient statistical power. Studies that simultaneously investigate change of network ties and change of nodal attributes (selection and influence studies) are particularly at risk because the number of nodal observations is typically much lower than the number of observed tie variables. This article presents a simulation-based procedure to evaluate statistical power of longitudinal social network studies in which stochastic actor-oriented models are to be applied. Two detailed case studies illustrate how statistical power is strongly affected by network size, number of data collection waves, effect sizes, missing data, and participant turnover. These issues should thus be explored in the design phase of longitudinal social network studies.},
	language = {en},
	number = {4},
	urldate = {2024-07-03},
	journal = {Sociological Methods \& Research},
	author = {Stadtfeld, Christoph and Snijders, Tom A. B. and Steglich, Christian and van Duijn, Marijtje},
	month = nov,
	year = {2020},
	pages = {1103--1132},
}
@article{mcfarland_big_2015,
	title = {Big {Data} and the danger of being precisely inaccurate},
	volume = {2},
	issn = {2053-9517},
	url = {https://doi.org/10.1177/2053951715602495},
	doi = {10.1177/2053951715602495},
	abstract = {Social scientists and data analysts are increasingly making use of Big Data in their analyses. These data sets are often “found data” arising from purely observational sources rather than data derived under strict rules of a statistically designed experiment. However, since these large data sets easily meet the sample size requirements of most statistical procedures, they give analysts a false sense of security as they proceed to focus on employing traditional statistical methods. We explain how most analyses performed on Big Data today lead to “precisely inaccurate” results that hide biases in the data but are easily overlooked due to the enhanced significance of the results created by the data size. Before any analyses are performed on large data sets, we recommend employing a simple data segmentation technique to control for some major components of observational data biases. These segments will help to improve the accuracy of the results.},
	language = {en},
	number = {2},
	urldate = {2023-11-10},
	journal = {Big Data \& Society},
	author = {McFarland, Daniel A and McFarland, H Richard},
	month = dec,
	year = {2015},
	pages = {2053951715602495},
}
@article{freese_emergence_2018,
	title = {The {Emergence} of {Statistical} {Objectivity}: {Changing} {Ideas} of {Epistemic} {Vice} and {Virtue} in {Science}},
	volume = {36},
	issn = {0735-2751},
	shorttitle = {The {Emergence} of {Statistical} {Objectivity}},
	url = {https://doi.org/10.1177/0735275118794987},
	doi = {10.1177/0735275118794987},
	abstract = {The meaning of objectivity in any specific setting reflects historically situated understandings of both science and self. Recently, various scientific fields have confronted growing mistrust about the replicability of findings, and statistical techniques have been deployed to articulate a “crisis of false positives.” In response, epistemic activists have invoked a decidedly economic understanding of scientists’ selves. This has prompted a scientific social movement of proposed reforms, including regulating disclosure of “backstage” research details and enhancing incentives for replication. We theorize that together, these events represent the emergence of a new formulation of objectivity. Statistical objectivity assesses the integrity of research literatures in the results observed in collections of studies rather than the methodological details of individual studies and thus positions meta-analysis as the ultimate arbiter of scientific objectivity. Statistical objectivity presents a challenge to scientific communities and raises new questions for sociological theory about tensions between quantification and expertise.},
	language = {en},
	number = {3},
	urldate = {2024-07-03},
	journal = {Sociological Theory},
	author = {Freese, Jeremy and Peterson, David},
	month = sep,
	year = {2018},
}
@inproceedings{vaswani_attention_2017,
	address = {Red Hook, NY, USA},
	series = {{NIPS}'17},
	title = {Attention is all you need},
	isbn = {978-1-5108-6096-4},
	abstract = {The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring significantly less time to train. Our model achieves 28.4 BLEU on the WMT 2014 English-to-German translation task, improving over the existing best results, including ensembles, by over 2 BLEU. On the WMT 2014 English-to-French translation task, our model establishes a new single-model state-of-the-art BLEU score of 41.0 after training for 3.5 days on eight GPUs, a small fraction of the training costs of the best models from the literature.},
	urldate = {2024-08-05},
	booktitle = {Proceedings of the 31st {International} {Conference} on {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates Inc.},
	author = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and Kaiser, Łukasz and Polosukhin, Illia},
	month = dec,
	year = {2017},
	pages = {6000--6010},
	file = {Full Text PDF:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/APKZEXW4/Vaswani et al. - 2017 - Attention is all you need.pdf:application/pdf},
}
@misc{wang_large_2024,
	title = {Large language models cannot replace human participants because they cannot portray identity groups},
	url = {http://arxiv.org/abs/2402.01908},
	doi = {10.48550/arXiv.2402.01908},
	abstract = {Large language models (LLMs) are increasing in capability and popularity, propelling their application in new domains -- including as replacements for human participants in computational social science, user testing, annotation tasks, and more. Traditionally, in all of these settings survey distributors are careful to find representative samples of the human population to ensure the validity of their results and understand potential demographic differences. This means in order to be a suitable replacement, LLMs will need to be able to capture the influence of positionality (i.e., relevance of social identities like gender and race). However, we show that there are two inherent limitations in the way current LLMs are trained that prevent this. We argue analytically for why LLMs are doomed to both misportray and flatten the representations of demographic groups, then empirically show this to be true on 4 LLMs through a series of human studies with 3200 participants across 16 demographic identities. We also discuss a third consideration about how identity prompts can essentialize identities. Throughout, we connect each of these limitations to a pernicious history that shows why each is harmful for marginalized demographic groups. Overall, we urge caution in use cases where LLMs are intended to replace human participants whose identities are relevant to the task at hand. At the same time, in cases where the goal is to supplement rather than replace (e.g., pilot studies), we provide empirically-better inference-time techniques to reduce, but not remove, these harms.},
	urldate = {2024-08-05},
	publisher = {arXiv},
	author = {Wang, Angelina and Morgenstern, Jamie and Dickerson, John P.},
	month = feb,
	year = {2024},
}
@article{abdurahman2024perils,
    author = {Abdurahman, Suhaib and Atari, Mohammad and Karimi-Malekabadi, Farzan and Xue, Mona J. and Trager, Jackson and Park, Peter S. and Golazizian, Preni and Omrani, Ali and Dehghani, Morteza},
    title = "{Perils and opportunities in using large language models in psychological research}",
    journal = {PNAS Nexus},
    volume = {3},
    number = {7},
    year = {2024},
    month = {07},
    abstract = "{The emergence of large language models (LLMs) has sparked considerable interest in their potential application in psychological research, mainly as a model of the human psyche or as a general text-analysis tool. However, the trend of using LLMs without sufficient attention to their limitations and risks, which we rhetorically refer to as “GPTology”, can be detrimental given the easy access to models such as ChatGPT. Beyond existing general guidelines, we investigate the current limitations, ethical implications, and potential of LLMs specifically for psychological research, and show their concrete impact in various empirical studies. Our results highlight the importance of recognizing global psychological diversity, cautioning against treating LLMs (especially in zero-shot settings) as universal solutions for text analysis, and developing transparent, open methods to address LLMs’ opaque nature for reliable, reproducible, and robust inference from AI-generated data. Acknowledging LLMs’ utility for task automation, such as text annotation, or to expand our understanding of human psychology, we argue for diversifying human samples and expanding psychology’s methodological toolbox to promote an inclusive, generalizable science, countering homogenization, and over-reliance on LLMs.}",
    doi = {10.1093/pnasnexus/pgae245},
}

@article{bradley2021unrepresentative,
  title={Unrepresentative big surveys significantly overestimated US vaccine uptake},
  author={Bradley, Valerie C. and Kuriwaki, Shiro and Isakov, Michael and Sejdinovic, Dino and Meng, Xiao-Li and Flaxman, Seth},
  journal={Nature},
  volume={600},
  number={7890},
  pages={695--700},
  year={2021},
}
@article{berinsky_evaluating_2012,
	title = {Evaluating {Online} {Labor} {Markets} for {Experimental} {Research}: {Amazon}.com's {Mechanical} {Turk}},
	volume = {20},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Evaluating {Online} {Labor} {Markets} for {Experimental} {Research}},
	url = {https://www.cambridge.org/core/journals/political-analysis/article/evaluating-online-labor-markets-for-experimental-research-amazoncoms-mechanical-turk/348F95C0FBCF21C3B37D66EB432F3BA5},
	doi = {10.1093/pan/mpr057},
	abstract = {We examine the trade-offs associated with using Amazon.com's Mechanical Turk (MTurk) interface for subject recruitment. We first describe MTurk and its promise as a vehicle for performing low-cost and easy-to-field experiments. We then assess the internal and external validity of experiments performed using MTurk, employing a framework that can be used to evaluate other subject pools. We first investigate the characteristics of samples drawn from the MTurk population. We show that respondents recruited in this manner are often more representative of the U.S. population than in-person convenience samples—the modal sample in published experimental political science—but less representative than subjects in Internet-based panels or national probability samples. Finally, we replicate important published experimental work using MTurk samples.},
	language = {en},
	number = {3},
	urldate = {2024-08-07},
	journal = {Political Analysis},
	author = {Berinsky, Adam J. and Huber, Gregory A. and Lenz, Gabriel S.},
	month = jul,
	year = {2012},
	pages = {351--368},
}
@article{zack_can_2019,
	title = {Can {Nonprobability} {Samples} be {Used} for {Social} {Science} {Research}? {A} cautionary tale},
	shorttitle = {Can {Nonprobability} {Samples} be {Used} for {Social} {Science} {Research}?},
	url = {https://ojs.ub.uni-konstanz.de/srm/article/view/7262},
	doi = {10.18148/SRM/2019.V13I2.7262},
	abstract = {Survey researchers and social scientists are trying to understand the appropriate use of nonprobability samples as substitutes for probability samples in social science research. While cognizant of the challenges presented by nonprobability samples, scholars increasingly rely on these samples due to their low cost and speed of data collection. This paper contributes to the growing literature on the appropriate use of nonprobability samples by comparing two online non-probability samples, Amazon’s Mechanical Turk (MTurk) and a Qualtrics Panel, with a gold standard nationally representative probability sample, the GSS. Most research in this area focuses on determining the best techniques to improve point estimates from nonprobability samples, often using gold standard surveys or census data to determine the accuracy of the point estimates. This paper differs from that line of research in that we examine how probability and nonprobability samples differ when used in multivariate analysis, the research technique used by many social scientists. Additionally, we examine whether restricting each sample to a population well-represented in MTurk (Americans age 45 and under) improves MTurk’s estimates. We find that, while Qualtrics and MTurk differ somewhat from the GSS, Qualtrics outperforms MTurk in both univariate and multivariate analysis. Further, restricting the samples substantially improves MTurk’s estimates, almost closing the gap with Qualtrics. With both Qualtrics and MTurk, we find a risk of false positives. Our findings suggest that these online nonprobability samples may sometimes be ‘fit for purpose,’ but should be used with caution.},
	language = {en},
	urldate = {2024-08-07},
	journal = {Survey Research Methods},
	author = {Zack, Elizabeth S. and Kennedy, John and Long, J. Scott},
	month = jun,
	year = {2019},
	pages = {215--227},
}
@misc{kim_ai-augmented_2024,
	title = {{AI}-{Augmented} {Surveys}: {Leveraging} {Large} {Language} {Models} and {Surveys} for {Opinion} {Prediction}},
	shorttitle = {{AI}-{Augmented} {Surveys}},
	url = {http://arxiv.org/abs/2305.09620},
	abstract = {Large language models (LLMs) that produce human-like responses have begun to revolutionize research practices in the social sciences. We develop a novel methodological framework that fine-tunes LLMs with repeated cross-sectional surveys to incorporate the meaning of survey questions, individual beliefs, and temporal contexts for opinion prediction. We introduce two new emerging applications of the AI-augmented survey: retrodiction (i.e., predict year-level missing responses) and unasked opinion prediction (i.e., predict entirely missing responses). Among 3,110 binarized opinions from 68,846 Americans in the General Social Survey from 1972 to 2021, our models based on Alpaca-7b excel in retrodiction (AUC = 0.86 for personal opinion prediction, ρ = 0.98 for public opinion prediction). These remarkable prediction capabilities allow us to fill in missing trends with high confidence and pinpoint when public attitudes changed, such as the rising support for same-sex marriage. On the other hand, our fine-tuned Alpaca-7b models show modest success in unasked opinion prediction (AUC = 0.73, ρ = 0.67). We discuss practical constraints and ethical concerns regarding individual autonomy and privacy when using LLMs for opinion prediction. Our study demonstrates that LLMs and surveys can mutually enhance each other’s capabilities: LLMs can broaden survey potential, while surveys can improve the alignment of LLMs.},
	language = {en},
	urldate = {2024-08-09},
	publisher = {arXiv},
	author = {Kim, Junsol and Lee, Byungkyu},
	month = apr,
	year = {2024},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Computer Science - Computation and Language},
}
@misc{ashokkumar_predicting_2024,
	title = {Predicting {Results} of {Social} {Science} {Experiments} {Using} {Large} {Language} {Models}},
	url = {https://docsend.com/view/ity6yf2dansesucf},
	language = {en},
	urldate = {2024-08-08},
	author = {Ashokkumar, Ashwini and Hewitt, Luke and Ghezae, Isaias and Willer, Robb},
	month = aug,
	year = {2024},
}
@article{lovakov_empirically_2021,
	title = {Empirically derived guidelines for effect size interpretation in social psychology},
	volume = {51},
	copyright = {© 2021 John Wiley \& Sons, Ltd.},
	issn = {1099-0992},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/ejsp.2752},
	doi = {10.1002/ejsp.2752},
	abstract = {This study estimates empirically derived guidelines for effect size interpretation for research in social psychology overall and sub-disciplines within social psychology, based on analysis of the true distributions of the two types of effect size measures widely used in social psychology (correlation coefficient and standardized mean differences). Analysis of empirically derived distributions of 12,170 correlation coefficients and 6,447 Cohen's d statistics extracted from studies included in 134 published meta-analyses revealed that the 25th, 50th, and 75th percentiles corresponded to correlation coefficient values of 0.12, 0.24, and 0.41 and to Cohen's d values of 0.15, 0.36, and 0.65 respectively. The analysis suggests that the widely used Cohen's guidelines tend to overestimate medium and large effect sizes. Empirically derived effect size distributions in social psychology overall and its sub-disciplines can be used both for effect size interpretation and for sample size planning when other information about effect size is not available.},
	language = {en},
	number = {3},
	urldate = {2024-08-05},
	journal = {European Journal of Social Psychology},
	author = {Lovakov, Andrey and Agadullina, Elena R.},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1002/ejsp.2752},
	keywords = {correlation, effect size, sample size, Cohen's d},
	pages = {485--504},
}
@article{chandler_online_2019,
	title = {Online panels in social science research: {Expanding} sampling methods beyond {Mechanical} {Turk}},
	volume = {51},
	issn = {1554-3528},
	shorttitle = {Online panels in social science research},
	url = {https://doi.org/10.3758/s13428-019-01273-7},
	doi = {10.3758/s13428-019-01273-7},
	abstract = {Amazon Mechanical Turk (MTurk) is widely used by behavioral scientists to recruit research participants. MTurk offers advantages over traditional student subject pools, but it also has important limitations. In particular, the MTurk population is small and potentially overused, and some groups of interest to behavioral scientists are underrepresented and difficult to recruit. Here we examined whether online research panels can avoid these limitations. Specifically, we compared sample composition, data quality (measured by effect sizes, internal reliability, and attention checks), and the non-naivete of participants recruited from MTurk and Prime Panels—an aggregate of online research panels. Prime Panels participants were more diverse in age, family composition, religiosity, education, and political attitudes. Prime Panels participants also reported less exposure to classic protocols and produced larger effect sizes, but only after screening out several participants who failed a screening task. We conclude that online research panels offer a unique opportunity for research, yet one with some important trade-offs.},
	language = {en},
	number = {5},
	urldate = {2024-08-08},
	journal = {Behavior Research Methods},
	author = {Chandler, Jesse and Rosenzweig, Cheskie and Moss, Aaron J. and Robinson, Jonathan and Litman, Leib},
	month = oct,
	year = {2019},
	keywords = {Data collection, Mechanical Turk, Online experimentation, Prime panels},
	pages = {2022--2038},
}
@article{levay_demographic_2016,
	title = {The {Demographic} and {Political} {Composition} of {Mechanical} {Turk} {Samples}},
	volume = {6},
	issn = {2158-2440},
	url = {https://doi.org/10.1177/2158244016636433},
	doi = {10.1177/2158244016636433},
	abstract = {One of the most notable recent developments in survey research is the increased usage of online convenience samples drawn from Amazon’s Mechanical Turk (MTurk). While scholars have noted various social and political differences (e.g., age, partisanship) between MTurk and population-based samples, the breadth and depth of these variations remain unclear. We investigate the extent to which MTurk samples differ from population samples, and the underlying nature of these differences. We do so by replicating items from the population-based American National Election Studies (ANES) 2012 Time Series Study in a survey administered to a sample of MTurk respondents. With few exceptions, we not only find that MTurk respondents differ significantly from respondents completing the 2012 ANES via the Web but also that most differences are reduced considerably when controlling for easily measurable sample features. Thus, MTurk respondents do not appear to differ fundamentally from population-based respondents in unmeasurable ways. This suggests that MTurk data can be used to advance research programs, particularly if researchers measure and account for a range of political and demographic variables as needed.},
	language = {en},
	number = {1},
	urldate = {2024-08-07},
	journal = {Sage Open},
	author = {Levay, Kevin E. and Freese, Jeremy and Druckman, James N.},
	month = jan,
	year = {2016},
	pages = {1-17},
}
@misc{voelkel_megastudy_2023,
	title = {Megastudy identifying effective interventions to strengthen {Americans}’ democratic attitudes},
	url = {https://osf.io/preprints/osf/y79u5},
	language = {en-us},
	urldate = {2024-07-29},
	author = {Voelkel, Jan G. and Stagnaro, Michael and Chu, James and Pink, Sophia L. and Mernyk, Joseph S. and Redekopp, Chrystal and Ghezae, et al., Isaias},
	month = mar,
	year = {2023},
}
@article{dellavigna_what_2018,
	title = {What {Motivates} {Effort}? {Evidence} and {Expert} {Forecasts}},
	volume = {85},
	issn = {0034-6527},
	shorttitle = {What {Motivates} {Effort}?},
	url = {https://doi.org/10.1093/restud/rdx033},
	doi = {10.1093/restud/rdx033},
	abstract = {How much do different monetary and non-monetary motivators induce costly effort? Does the effectiveness line up with the expectations of researchers and with results in the literature? We conduct a large-scale real-effort experiment with eighteen treatment arms. We examine the effect of (1) standard incentives; (2) behavioural factors like social preferences and reference dependence; and (3) non-monetary inducements from psychology. We find that (1) monetary incentives work largely as expected, including a very low piece rate treatment which does not crowd out effort; (2) the evidence is partly consistent with standard behavioural models, including warm glow, though we do not find evidence of probability weighting; (3) the psychological motivators are effective, but less so than incentives. We then compare the results to forecasts by 208 academic experts. On average, the experts anticipate several key features, like the effectiveness of psychological motivators. A sizeable share of experts, however, expects crowd-out, probability weighting, and pure altruism, counterfactually. As a further comparison, we present a meta-analysis of similar treatments in the literature. Overall, predictions based on the literature are correlated with, but underperform, the expert forecasts.},
	number = {2},
	urldate = {2024-06-15},
	journal = {The Review of Economic Studies},
	author = {DellaVigna, Stefano and Pope, Devin},
	month = apr,
	year = {2018},
	pages = {1029--1069},
}
@article{milkman_megastudies_2021,
	title = {Megastudies improve the impact of applied behavioural science},
	volume = {600},
	copyright = {2021 The Author(s), under exclusive licence to Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-021-04128-4},
	doi = {10.1038/s41586-021-04128-4},
	abstract = {Policy-makers are increasingly turning to behavioural science for insights about how to improve citizens’ decisions and outcomes1. Typically, different scientists test different intervention ideas in different samples using different outcomes over different time intervals2. The lack of comparability of such individual investigations limits their potential to inform policy. Here, to address this limitation and accelerate the pace of discovery, we introduce the megastudy—a massive field experiment in which the effects of many different interventions are compared in the same population on the same objectively measured outcome for the same duration. In a megastudy targeting physical exercise among 61,293 members of an American fitness chain, 30 scientists from 15 different US universities worked in small independent teams to design a total of 54 different four-week digital programmes (or interventions) encouraging exercise. We show that 45\% of these interventions significantly increased weekly gym visits by 9\% to 27\%; the top-performing intervention offered microrewards for returning to the gym after a missed workout. Only 8\% of interventions induced behaviour change that was significant and measurable after the four-week intervention. Conditioning on the 45\% of interventions that increased exercise during the intervention, we detected carry-over effects that were proportionally similar to those measured in previous research3–6. Forecasts by impartial judges failed to predict which interventions would be most effective, underscoring the value of testing many ideas at once and, therefore, the potential for megastudies to improve the evidentiary value of behavioural science.},
	language = {en},
	number = {7889},
	urldate = {2024-08-08},
	journal = {Nature},
	author = {Milkman, Katherine L. and Gromet, Dena and Ho, Hung and Kay, Joseph S. and Lee, Timothy W. and Pandiloski, Pepi and Park, Yeji and Rai, Aneesh and Bazerman, Max and Beshears, John and Bonacorsi, Lauri and Camerer, Colin and Chang, Edward and Chapman, Gretchen and Cialdini, Robert and Dai, Hengchen and Eskreis-Winkler, Lauren and Fishbach, Ayelet and Gross, James J. and Horn, Samantha and Hubbard, Alexa and Jones, Steven J. and Karlan, Dean and Kautz, Tim and Kirgios, Erika and Klusowski, Joowon and Kristal, Ariella and Ladhania, Rahul and Loewenstein, George and Ludwig, Jens and Mellers, Barbara and Mullainathan, Sendhil and Saccardo, Silvia and Spiess, Jann and Suri, Gaurav and Talloen, Joachim H. and Taxer, Jamie and Trope, Yaacov and Ungar, Lyle and Volpp, Kevin G. and Whillans, Ashley and Zinman, Jonathan and Duckworth, Angela L.},
	month = dec,
	year = {2021},
	keywords = {Decision making, Human behaviour},
	pages = {478--483},
}
@misc{gelman_you_2018,
	title = {You need 16 times the sample size to estimate an interaction than to estimate a main effect {\textbar} {Statistical} {Modeling}, {Causal} {Inference}, and {Social} {Science}},
	url = {https://statmodeling.stat.columbia.edu/2018/03/15/need16/},
	urldate = {2024-07-29},
	journal = {Statistical Modeling, Causal Inference, and Social Science},
	author = {Gelman, Andrew},
	month = mar,
	year = {2018},
}
@article{faul_statistical_2009,
	title = {Statistical power analyses using {G}*{Power} 3.1: {Tests} for correlation and regression analyses},
	volume = {41},
	issn = {1554-3528},
	shorttitle = {Statistical power analyses using {G}*{Power} 3.1},
	url = {https://doi.org/10.3758/BRM.41.4.1149},
	doi = {10.3758/BRM.41.4.1149},
	abstract = {G*Power is a free power analysis program for a variety of statistical tests. We present extensions and improvements of the version introduced by Faul, Erdfelder, Lang, and Buchner (2007) in the domain of correlation and regression analyses. In the new version, we have added procedures to analyze the power of tests based on (1) single-sample tetrachoric correlations, (2) comparisons of dependent correlations, (3) bivariate linear regression, (4) multiple linear regression based on the random predictor model, (5) logistic regression, and (6) Poisson regression. We describe these new features and provide a brief introduction to their scope and handling.},
	language = {en},
	number = {4},
	urldate = {2024-07-27},
	journal = {Behavior Research Methods},
	author = {Faul, Franz and Erdfelder, Edgar and Buchner, Axel and Lang, Albert-Georg},
	month = nov,
	year = {2009},
	keywords = {Effect Size Measure, Implicit Association Test, Linear Multiple Regression, Multiple Correlation Coefficient, Noncentrality Parameter},
	pages = {1149--1160},
	file = {Full Text PDF:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/PR2QYA8R/Faul et al. - 2009 - Statistical power analyses using GPower 3.1 Test.pdf:application/pdf},
}
@book{apostol_calculus_1969,
	address = {New York},
	edition = {2nd},
	title = {Calculus {Vol}. {II}},
	publisher = {Wiley \& Sons},
	author = {Apostol, Tom},
	year = {1969},
}
@book{rice_mathematical_2007,
	address = {Belmont, CA},
	edition = {3rd},
	series = {Duxbury advanced series},
	title = {Mathematical statistics and data analysis},
	isbn = {978-0-534-39942-9},
	language = {en},
	publisher = {Thomson/Brooks/Cole},
	author = {Rice, John A.},
	year = {2007},
}
@article{thye_reliability_2000,
	title = {Reliability in {Experimental} {Sociology}},
	volume = {78},
	issn = {0037-7732},
	url = {https://doi.org/10.1093/sf/78.4.1277},
	doi = {10.1093/sf/78.4.1277},
	abstract = {Although scientists from various disciplines stress the importance of estimating random measurement error, these discussions have little effect on experimenters who do behavioral sociological research. There have been two important results: (i) many experimenters continue to adopt a laissez-faire approach to measurement error, and there are very few discussions that illustrate its practical importance in laboratory research. In this article I examine the role of abstract measurement theory in modern experimental sociology giving particular emphasis to the improvement of data analysis and theory building. I detail the cause and effect of random measurement error in the laboratory and review how the reliability of behavioral data is estimated and interpreted. Discussed are issues of statistical power. Type I and Type II errors, internal and external validity, and the prospects for cumulative theory.},
	number = {4},
	urldate = {2024-07-03},
	journal = {Social Forces},
	author = {Thye, Shane R.},
	month = jun,
	year = {2000},
	pages = {1277--1309},
}
@article{stantcheva_how_2023,
	title = {How to {Run} {Surveys}: {A} {Guide} to {Creating} {Your} {Own} {Identifying} {Variation} and {Revealing} the {Invisible}},
	volume = {15},
	issn = {1941-1383, 1941-1391},
	shorttitle = {How to {Run} {Surveys}},
	url = {https://www.annualreviews.org/content/journals/10.1146/annurev-economics-091622-010157},
	doi = {10.1146/annurev-economics-091622-010157},
	abstract = {Surveys are an essential approach for eliciting otherwise invisible factors such as perceptions, knowledge and beliefs, attitudes, and reasoning. These factors are critical determinants of social, economic, and political outcomes. Surveys are not merely a research tool. They are also not only a way of collecting data. Instead, they involve creating the process that will generate the data. This allows the researcher to create their own identifying and controlled variation. Thanks to the rise of mobile technologies and platforms, surveys offer valuable opportunities either to study broadly representative samples or to focus on specific groups. This article offers guidance on the complete survey process, from the design of the questions and experiments to the recruitment of respondents and the collection of data to the analysis of survey responses. It covers issues related to the sampling process, selection and attrition, attention and carelessness, survey question design and measurement, response biases, and survey experiments.},
	language = {en},
	number = {Volume 15, 2023},
	urldate = {2024-08-13},
	journal = {Annual Review of Economics},
	author = {Stantcheva, Stefanie},
	month = sep,
	year = {2023},
	pages = {205--234},
}

@misc{lewis_retrieval-augmented_2021,
	title = {Retrieval-{Augmented} {Generation} for {Knowledge}-{Intensive} {NLP} {Tasks}},
	url = {http://arxiv.org/abs/2005.11401},
	doi = {10.48550/arXiv.2005.11401},
	abstract = {Large pre-trained language models have been shown to store factual knowledge in their parameters, and achieve state-of-the-art results when fine-tuned on downstream NLP tasks. However, their ability to access and precisely manipulate knowledge is still limited, and hence on knowledge-intensive tasks, their performance lags behind task-specific architectures. Additionally, providing provenance for their decisions and updating their world knowledge remain open research problems. Pre-trained models with a differentiable access mechanism to explicit non-parametric memory can overcome this issue, but have so far been only investigated for extractive downstream tasks. We explore a general-purpose fine-tuning recipe for retrieval-augmented generation (RAG) -- models which combine pre-trained parametric and non-parametric memory for language generation. We introduce RAG models where the parametric memory is a pre-trained seq2seq model and the non-parametric memory is a dense vector index of Wikipedia, accessed with a pre-trained neural retriever. We compare two RAG formulations, one which conditions on the same retrieved passages across the whole generated sequence, the other can use different passages per token. We fine-tune and evaluate our models on a wide range of knowledge-intensive NLP tasks and set the state-of-the-art on three open domain QA tasks, outperforming parametric seq2seq models and task-specific retrieve-and-extract architectures. For language generation tasks, we find that RAG models generate more specific, diverse and factual language than a state-of-the-art parametric-only seq2seq baseline.},
	urldate = {2024-08-14},
	publisher = {arXiv},
	author = {Lewis, Patrick and Perez, Ethan and Piktus, Aleksandra and Petroni, Fabio and Karpukhin, Vladimir and Goyal, Naman and Küttler, Heinrich and Lewis, Mike and Yih, Wen-tau and Rocktäschel, Tim and Riedel, Sebastian and Kiela, Douwe},
	month = apr,
	year = {2021},
	note = {arXiv:2005.11401 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
}
@article{Bisbee2024synthetic, title={Synthetic Replacements for Human Survey Data? The Perils of Large Language Models}, DOI={10.1017/pan.2024.5}, journal={Political Analysis}, author={Bisbee, James and Clinton, Joshua D. and Dorff, Cassy and Kenkel, Brenton and Larson, Jennifer M.}, year={2024}, pages={1–16}}
@article{rauf_audit_2024,
	title = {An {Audit} of {Social} {Science} {Survey} {Experiments}},
	url = {https://osf.io/https://osf.io/w4x5q?view_only=f4bd4d1cecbf4c4ca33763a61e2abf66},
	abstract = {Presented by OSF},
	language = {en-us},
	urldate = {2024-08-13},
	author = {Rauf, Tamkinat and Voelkel, Jan G. and Druckman, James and Freese, Jeremy},
	month = aug,
	year = {2024},
	note = {Publisher: Open Science Framework},
}
@misc{kallus_role_2024,
	title = {On the role of surrogates in the efficient estimation of treatment effects with limited outcome data},
	url = {http://arxiv.org/abs/2003.12408},
	doi = {10.48550/arXiv.2003.12408},
	abstract = {In many experiments and observational studies, the outcome of interest is often difficult or expensive to observe, reducing effective sample sizes for estimating average treatment effects (ATEs) even when identifiable. We study how incorporating data on units for which only surrogate outcomes not of primary interest are observed can increase the precision of ATE estimation. We refrain from imposing stringent surrogacy conditions, which permit surrogates as perfect replacements for the target outcome. Instead, we supplement the available, albeit limited, observations of the target outcome (which by themselves identify the ATE) with abundant observations of surrogate outcomes, without any assumptions beyond random assignment and missingness and corresponding overlap conditions. To quantify the potential gains, we derive the difference in efficiency bounds on ATE estimation with and without surrogates, both when an overwhelming or comparable number of units have missing outcomes. We develop robust ATE estimation and inference methods that realize these efficiency gains. We empirically demonstrate the gains by studying the long-term-earning effects of job training.},
	urldate = {2024-08-15},
	publisher = {arXiv},
	author = {Kallus, Nathan and Mao, Xiaojie},
	month = may,
	year = {2024},
	note = {arXiv:2003.12408 [cs, stat]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
}
@misc{egami_using_2024-1,
	title = {Using {Imperfect} {Surrogates} for {Downstream} {Inference}: {Design}-based {Supervised} {Learning} for {Social} {Science} {Applications} of {Large} {Language} {Models}},
	shorttitle = {Using {Imperfect} {Surrogates} for {Downstream} {Inference}},
	url = {http://arxiv.org/abs/2306.04746},
	doi = {10.48550/arXiv.2306.04746},
	abstract = {In computational social science (CSS), researchers analyze documents to explain social and political phenomena. In most scenarios, CSS researchers first obtain labels for documents and then explain labels using interpretable regression analyses in the second step. One increasingly common way to annotate documents cheaply at scale is through large language models (LLMs). However, like other scalable ways of producing annotations, such surrogate labels are often imperfect and biased. We present a new algorithm for using imperfect annotation surrogates for downstream statistical analyses while guaranteeing statistical properties -- like asymptotic unbiasedness and proper uncertainty quantification -- which are fundamental to CSS research. We show that direct use of surrogate labels in downstream statistical analyses leads to substantial bias and invalid confidence intervals, even with high surrogate accuracy of 80-90\%. To address this, we build on debiased machine learning to propose the design-based supervised learning (DSL) estimator. DSL employs a doubly-robust procedure to combine surrogate labels with a smaller number of high-quality, gold-standard labels. Our approach guarantees valid inference for downstream statistical analyses, even when surrogates are arbitrarily biased and without requiring stringent assumptions, by controlling the probability of sampling documents for gold-standard labeling. Both our theoretical analysis and experimental results show that DSL provides valid statistical inference while achieving root mean squared errors comparable to existing alternatives that focus only on prediction without inferential guarantees.},
	urldate = {2024-08-15},
	publisher = {arXiv},
	author = {Egami, Naoki and Hinck, Musashi and Stewart, Brandon M. and Wei, Hanying},
	month = jan,
	year = {2024},
	note = {arXiv:2306.04746 [cs, stat]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
}
@article{almaatouq_empirica_2021,
	title = {Empirica: a virtual lab for high-throughput macro-level experiments},
	volume = {53},
	issn = {1554-3528},
	shorttitle = {Empirica},
	url = {https://doi.org/10.3758/s13428-020-01535-9},
	doi = {10.3758/s13428-020-01535-9},
	abstract = {Virtual labs allow researchers to design high-throughput and macro-level experiments that are not feasible in traditional in-person physical lab settings. Despite the increasing popularity of online research, researchers still face many technical and logistical barriers when designing and deploying virtual lab experiments. While several platforms exist to facilitate the development of virtual lab experiments, they typically present researchers with a stark trade-off between usability and functionality. We introduce Empirica: a modular virtual lab that offers a solution to the usability–functionality trade-off by employing a “flexible defaults” design strategy. This strategy enables us to maintain complete “build anything” flexibility while offering a development platform that is accessible to novice programmers. Empirica’s architecture is designed to allow for parameterizable experimental designs, reusable protocols, and rapid development. These features will increase the accessibility of virtual lab experiments, remove barriers to innovation in experiment design, and enable rapid progress in the understanding of human behavior.},
	language = {en},
	number = {5},
	urldate = {2024-01-14},
	journal = {Behavior Research Methods},
	author = {Almaatouq, Abdullah and Becker, Joshua and Houghton, James P. and Paton, Nicolas and Watts, Duncan J. and Whiting, Mark E.},
	month = oct,
	year = {2021},
	keywords = {Crowdsourcing, Online research, Virtual lab},
	pages = {2158--2171},
}


@article{lazer_computational_2020,
	title = {Computational social science: {Obstacles} and opportunities},
	volume = {369},
	shorttitle = {Computational social science},
	url = {https://www.science.org/doi/10.1126/science.aaz8170},
	doi = {10.1126/science.aaz8170},
	number = {6507},
	urldate = {2023-07-03},
	journal = {Science},
	author = {Lazer, David M. J. and Pentland, Alex and Watts, Duncan J. and Aral, Sinan and Athey, Susan and Contractor, Noshir and Freelon, Deen and Gonzalez-Bailon, Sandra and King, Gary and Margetts, Helen and Nelson, Alondra and Salganik, Matthew J. and Strohmaier, Markus and Vespignani, Alessandro and Wagner, Claudia},
	month = aug,
	year = {2020},
	pages = {1060--1062},
}


@article {jones2011bayesian,
	Title = {Bayesian models for subgroup analysis in clinical trials},
	Author = {Jones, Hayley E and Ohlssen, David I and Neuenschwander, Beat and Racine, Amy and Branson, Michael},
	DOI = {10.1177/1740774510396933},
	Number = {2},
	Volume = {8},
	Month = {April},
	Year = {2011},
	Journal = {Clinical trials (London, England)},
	ISSN = {1740-7745},
	Pages = {129—143},
	Abstract = {&lt;h4&gt;Background&lt;/h4&gt;In a pharmaceutical drug development setting, possible interactions between the treatment and particular baseline clinical or demographic factors are often of interest. However, the subgroup analysis required to investigate such associations remains controversial. Concerns with classical hypothesis testing approaches to the problem include low power, multiple testing, and the possibility of data dredging.&lt;h4&gt;Purpose&lt;/h4&gt;As an alternative to hypothesis testing, the use of shrinkage estimation techniques is investigated in the context of an exploratory post hoc subgroup analysis. A range of models that have been suggested in the literature are reviewed. Building on this, we explore a general modeling strategy, considering various options for shrinkage of effect estimates. This is applied to a case-study, in which evidence was available from seven-phase II-III clinical trials examining a novel therapy, and also to two artificial datasets with the same structure.&lt;h4&gt;Methods&lt;/h4&gt;Emphasis is placed on hierarchical modeling techniques, adopted within a Bayesian framework using freely available software. A range of possible subgroup model structures are applied, each incorporating shrinkage estimation techniques.&lt;h4&gt;Results&lt;/h4&gt;The investigation of the case-study showed little evidence of subgroup effects. Because inferences appeared to be consistent across a range of well-supported models, and model diagnostic checks showed no obvious problems, it seemed this conclusion was robust. It is reassuring that the structured shrinkage techniques appeared to work well in a situation where deeper inspection of the data suggested little evidence of subgroup effects.&lt;h4&gt;Limitations&lt;/h4&gt;The post hoc examination of subgroups should be seen as an exploratory analysis, used to help make better informed decisions regarding potential future studies examining specific subgroups. To a certain extent, the degree of understanding provided by such assessments will be limited by the quality and quantity of available data.&lt;h4&gt;Conclusions&lt;/h4&gt;In light of recent interest by health authorities into the use of subgroup analysis in the context of drug development, it appears that Bayesian approaches involving shrinkage techniques could play an important role in this area. Hopefully, the developments outlined here provide useful methodology for tackling such a problem, in-turn leading to better informed decisions regarding subgroups.},
	URL = {https://doi.org/10.1177/1740774510396933},
}
@misc{acs_2016,
	address = {Minneapolis},
	title = {2012-2016 {American} {Community} {Survey}},
	doi = {https://doi.org/10.18128/D010.V15.0},
	urldate = {2024-06-07},
	note = {IPUMS USA 10.18128/D010.V15.0 (Accessed June 7, 2024)},
	author = {Ruggles, Steven and Flood, Sarah and Sobek, Matthew and Backman, Daniel and Chen, Annie and Cooper, Grace and Richards, Stephanie and Rodgers, Renae and Schouweiler, Megan},
	year = {2024},
}
@article{gui2023challenge,
  title={The Challenge of Using LLMs to Simulate Human Behavior: A Causal Inference Perspective},
  author={Gui, George and Toubia, Olivier},
  year={2023}
}
@article{park2024diminished,
	title = {Diminished diversity-of-thought in a standard large language model},
	issn = {1554-3528},
	doi = {10.3758/s13428-023-02307-x},
	abstract = {We test whether large language models (LLMs) can be used to simulate human participants in social-science studies. To do this, we ran replications of 14 studies from the Many Labs 2 replication project with OpenAI's text-davinci-003 model, colloquially known as GPT-3.5. Based on our pre-registered analyses, we find that among the eight studies we could analyse, our GPT sample replicated 37.5\% of the original results and 37.5\% of the Many Labs 2 results. However, we were unable to analyse the remaining six studies due to an unexpected phenomenon we call the "correct answer" effect. Different runs of GPT-3.5 answered nuanced questions probing political orientation, economic preference, judgement, and moral philosophy with zero or near-zero variation in responses: with the supposedly "correct answer." In one exploratory follow-up study, we found that a "correct answer" was robust to changing the demographic details that precede the prompt. In another, we found that most but not all "correct answers" were robust to changing the order of answer choices. One of our most striking findings occurred in our replication of the Moral Foundations Theory survey results, where we found GPT-3.5 identifying as a political conservative in 99.6\% of the cases, and as a liberal in 99.3\% of the cases in the reverse-order condition. However, both self-reported 'GPT conservatives' and 'GPT liberals' showed right-leaning moral foundations. Our results cast doubts on the validity of using LLMs as a general replacement for human participants in the social sciences. Our results also raise concerns that a hypothetical AI-led future may be subject to a diminished diversity of thought.},
	language = {eng},
	journal = {Behavior Research Methods},
	author = {Park, Peter S. and Schoenegger, Philipp and Zhu, Chongyang},
	month = jan,
	year = {2024},
	pmid = {38194165},
	keywords = {Artificial intelligence, Demographic effects, Diversity of thought, GPT-3.5, Large language models, Many Labs 2, Order effects, Psychology, Replication, Social science},
	file = {Full Text:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/T65JTZHH/Park et al. - 2024 - Diminished diversity-of-thought in a standard larg.pdf:application/pdf},
}
@article{awad_moral_2018,
	title = {The {Moral} {Machine} experiment},
	volume = {563},
	copyright = {2018 Springer Nature Limited},
	issn = {1476-4687},
	url = {https://www.nature.com/articles/s41586-018-0637-6},
	doi = {10.1038/s41586-018-0637-6},
	abstract = {With the rapid development of artificial intelligence have come concerns about how machines will make moral decisions, and the major challenge of quantifying societal expectations about the ethical principles that should guide machine behaviour. To address this challenge, we deployed the Moral Machine, an online experimental platform designed to explore the moral dilemmas faced by autonomous vehicles. This platform gathered 40 million decisions in ten languages from millions of people in 233 countries and territories. Here we describe the results of this experiment. First, we summarize global moral preferences. Second, we document individual variations in preferences, based on respondents’ demographics. Third, we report cross-cultural ethical variation, and uncover three major clusters of countries. Fourth, we show that these differences correlate with modern institutions and deep cultural traits. We discuss how these preferences can contribute to developing global, socially acceptable principles for machine ethics. All data used in this article are publicly available.},
	language = {en},
	number = {7729},
	urldate = {2023-11-20},
	journal = {Nature},
	author = {Awad, Edmond and Dsouza, Sohan and Kim, Richard and Schulz, Jonathan and Henrich, Joseph and Shariff, Azim and Bonnefon, Jean-François and Rahwan, Iyad},
	month = nov,
	year = {2018},
	keywords = {Culture, Human behaviour, Ethics},
	pages = {59--64},
	file = {41586_2018_637_MOESM1_ESM.pdf:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/D73XNLRV/41586_2018_637_MOESM1_ESM.pdf:application/pdf;Awad et al. - 2018 - The Moral Machine experiment.pdf:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/EH7FBT7I/Awad et al. - 2018 - The Moral Machine experiment.pdf:application/pdf},
}

@article{hainmueller_causal_2014,
	title = {Causal {Inference} in {Conjoint} {Analysis}: {Understanding} {Multidimensional} {Choices} via {Stated} {Preference} {Experiments}},
	volume = {22},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Causal {Inference} in {Conjoint} {Analysis}},
	url = {https://www.cambridge.org/core/journals/political-analysis/article/causal-inference-in-conjoint-analysis-understanding-multidimensional-choices-via-stated-preference-experiments/414DA03BAA2ACE060FFE005F53EFF8C8},
	doi = {10.1093/pan/mpt024},
	abstract = {Survey experiments are a core tool for causal inference. Yet, the design of classical survey experiments prevents them from identifying which components of a multidimensional treatment are influential. Here, we show how conjoint analysis, an experimental design yet to be widely applied in political science, enables researchers to estimate the causal effects of multiple treatment components and assess several causal hypotheses simultaneously. In conjoint analysis, respondents score a set of alternatives, where each has randomly varied attributes. Here, we undertake a formal identification analysis to integrate conjoint analysis with the potential outcomes framework for causal inference. We propose a new causal estimand and show that it can be nonparametrically identified and easily estimated from conjoint data using a fully randomized design. The analysis enables us to propose diagnostic checks for the identification assumptions. We then demonstrate the value of these techniques through empirical applications to voter decision making and attitudes toward immigrants.},
	language = {en},
	number = {1},
	urldate = {2024-01-14},
	journal = {Political Analysis},
	author = {Hainmueller, Jens and Hopkins, Daniel J. and Yamamoto, Teppei},
	month = jan,
	year = {2014},
	pages = {1--30},
	file = {Hainmueller et al. - 2014 - Causal Inference in Conjoint Analysis Understandi.pdf:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/KS8BFDX4/Hainmueller et al. - 2014 - Causal Inference in Conjoint Analysis Understandi.pdf:application/pdf},
}
@article{lewis_studying_2015,
	title = {Studying {Online} {Behavior}: {Comment} on {Anderson} et al. 2014},
	volume = {2},
	issn = {23306696},
	shorttitle = {Studying {Online} {Behavior}},
	url = {http://www.sociologicalscience.com/articles-vol2-2and3-20/},
	doi = {10.15195/v2.a2},
	abstract = {As social scientists increasingly employ data from online sources, it is important that we acknowledge both the advantages and limitations of this research. The latter have received comparatively little public attention. In this comment, I argue that a recent article by Anderson and colleagues: 1) inadequately describes the study sample; 2) inadequately describes how the website operates; and 3) inadequately develops the paper’s central measures — such that it is difﬁcult to evaluate the generalizability, veracity, and importance of their claims and impossible to replicate their ﬁndings. These limitations are not unique to the Anderson et al. article; rather, they point to a set of concerns that all researchers in this growing and important line of study need to address if our work is to have enduring impact.},
	language = {en},
	urldate = {2023-11-10},
	journal = {Sociological Science},
	author = {Lewis, Kevin},
	year = {2015},
	pages = {20--31},
	file = {Lewis - 2015 - Studying Online Behavior Comment on Anderson et a.pdf:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/QZUALDQA/Lewis - 2015 - Studying Online Behavior Comment on Anderson et a.pdf:application/pdf},
}
@article{golder_digital_2014,
	title = {Digital {Footprints}: {Opportunities} and {Challenges} for {Online} {Social} {Research}},
	volume = {40},
	shorttitle = {Digital {Footprints}},
	url = {https://doi.org/10.1146/annurev-soc-071913-043145},
	doi = {10.1146/annurev-soc-071913-043145},
	abstract = {Online interaction is now a regular part of daily life for a demographically diverse population of hundreds of millions of people worldwide. These interactions generate fine-grained time-stamped records of human behavior and social interaction at the level of individual events, yet are global in scale, allowing researchers to address fundamental questions about social identity, status, conflict, cooperation, collective action, and diffusion, both by using observational data and by conducting in vivo field experiments. This unprecedented opportunity comes with a number of methodological challenges, including generalizing observations to the offline world, protecting individual privacy, and solving the logistical challenges posed by “big data” and web-based experiments. We review current advances in online social research and critically assess the theoretical and methodological opportunities and limitations. [J]ust as the invention of the telescope revolutionized the study of the heavens, so too by rendering the unmeasurable measurable, the technological revolution in mobile, Web, and Internet communications has the potential to revolutionize our understanding of ourselves and how we interact…. [T]hree hundred years after Alexander Pope argued that the proper study of mankind should lie not in the heavens but in ourselves, we have finally found our telescope. Let the revolution begin. —Duncan Watts (2011, p. 266)},
	number = {1},
	urldate = {2023-07-03},
	journal = {Annual Review of Sociology},
	author = {Golder, Scott A. and Macy, Michael W.},
	year = {2014},
	note = {\_eprint: https://doi.org/10.1146/annurev-soc-071913-043145},
	keywords = {social networks, Internet, social media, online networks, Web},
	pages = {129--152},
	file = {Full Text PDF:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/DQMH48PS/Golder and Macy - 2014 - Digital Footprints Opportunities and Challenges f.pdf:application/pdf},
}
@article{argyle_out_2023,
	title = {Out of {One}, {Many}: {Using} {Language} {Models} to {Simulate} {Human} {Samples}},
	volume = {31},
	issn = {1047-1987, 1476-4989},
	shorttitle = {Out of {One}, {Many}},
	url = {https://www.cambridge.org/core/journals/political-analysis/article/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49},
	doi = {10.1017/pan.2023.2},
	abstract = {We propose and explore the possibility that language models can be studied as effective proxies for specific human subpopulations in social science research. Practical and research applications of artificial intelligence tools have sometimes been limited by problematic biases (such as racism or sexism), which are often treated as uniform properties of the models. We show that the “algorithmic bias” within one such tool—the GPT-3 language model—is instead both fine-grained and demographically correlated, meaning that proper conditioning will cause it to accurately emulate response distributions from a wide variety of human subgroups. We term this property algorithmic fidelity and explore its extent in GPT-3. We create “silicon samples” by conditioning the model on thousands of sociodemographic backstories from real human participants in multiple large surveys conducted in the United States. We then compare the silicon and human samples to demonstrate that the information contained in GPT-3 goes far beyond surface similarity. It is nuanced, multifaceted, and reflects the complex interplay between ideas, attitudes, and sociocultural context that characterize human attitudes. We suggest that language models with sufficient algorithmic fidelity thus constitute a novel and powerful tool to advance understanding of humans and society across a variety of disciplines.},
	language = {en},
	number = {3},
	urldate = {2023-11-02},
	journal = {Political Analysis},
	author = {Argyle, Lisa P. and Busby, Ethan C. and Fulda, Nancy and Gubler, Joshua R. and Rytting, Christopher and Wingate, David},
	month = jul,
	year = {2023},
	keywords = {machine learning, computational social science, public opinion, artificial intelligence},
	pages = {337--351},
	file = {Full Text PDF:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/U4EU96GD/Argyle et al. - 2023 - Out of One, Many Using Language Models to Simulat.pdf:application/pdf},
}

@article{hoerl1970ridgea,
  title={Ridge regression: applications to nonorthogonal problems},
  author={Hoerl, Arthur E and Kennard, Robert W},
  journal={Technometrics},
  volume={12},
  number={1},
  pages={69--82},
  year={1970},
  publisher={Taylor \& Francis}
}

@article{hoerl1970ridgeb,
  title={Ridge regression: Biased estimation for nonorthogonal problems},
  author={Hoerl, Arthur E and Kennard, Robert W},
  journal={Technometrics},
  volume={12},
  number={1},
  pages={55--67},
  year={1970},
  publisher={Taylor \& Francis}
}

@article{geman1992neural,
  title={Neural networks and the bias/variance dilemma},
  author={Geman, Stuart and Bienenstock, Elie and Doursat, Ren{\'e}},
  journal={Neural computation},
  volume={4},
  number={1},
  pages={1--58},
  year={1992},
  publisher={MIT Press One Rogers Street, Cambridge, MA 02142-1209, USA journals-info~…}
}

@article{belkin2019reconciling,
  title={Reconciling modern machine-learning practice and the classical bias--variance trade-off},
  author={Belkin, Mikhail and Hsu, Daniel and Ma, Siyuan and Mandal, Soumik},
  journal={Proceedings of the National Academy of Sciences},
  volume={116},
  number={32},
  pages={15849--15854},
  year={2019},
  publisher={National Acad Sciences}
}

@misc{bisbee_synthetic_2023,
	title = {Synthetic {Replacements} for {Human} {Survey} {Data}? {The} {Perils} of {Large} {Language} {Models}},
	shorttitle = {Synthetic {Replacements} for {Human} {Survey} {Data}?},
	url = {https://osf.io/preprints/socarxiv/5ecfa/},
	doi = {10.31235/osf.io/5ecfa},
	abstract = {Large Language Models (LLMs) offer new research possibilities for social scientists, but their potential as "synthetic data" is still largely unknown. In this paper, we investigate how accurately the popular closed-source LLM ChatGPT can recover public opinion, prompting the LLM to adopt different "personas" and then provide feeling thermometer scores for 11 sociopolitical groups. The average scores generated by ChatGPT correspond closely to the averages in our baseline survey, the 2016–2020 American National Election Study. Nevertheless, sampling by ChatGPT is not reliable for statistical inference: there is less variation in responses than in the real surveys, and regression coefficients often differ significantly from equivalent estimates obtained using ANES data. We also document how the distribution of synthetic responses varies with minor changes in prompt wording, and we show how the same prompt yields significantly different results over a three-month period. Altogether, our findings raise serious concerns about the quality, reliability, and reproducibility of synthetic survey data generated by LLMs.},
	language = {en-us},
	urldate = {2023-11-05},
	publisher = {SocArXiv},
	author = {Bisbee, James and Clinton, Joshua and Dorff, Cassy and Kenkel, Brenton and Larson, Jennifer},
	month = may,
	year = {2023},
	keywords = {Political Science, Social and Behavioral Sciences, American Politics, Models and Methods},
	file = {Full Text PDF:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/9BS4B6XA/Bisbee et al. - 2023 - Synthetic Replacements for Human Survey Data The .pdf:application/pdf},
}

@article{chipman2010bart,
  title={BART: Bayesian additive regression trees},
  author={Chipman, Hugh A and George, Edward I and McCulloch, Robert E},
  year={2010}
}
@article{grossmann_ai_2023,
	title = {{AI} and the transformation of social science research},
	volume = {380},
	url = {https://www.science.org/doi/10.1126/science.adi1778},
	doi = {10.1126/science.adi1778},
	number = {6650},
	urldate = {2023-11-03},
	journal = {Science},
	author = {Grossmann, Igor and Feinberg, Matthew and Parker, Dawn C. and Christakis, Nicholas A. and Tetlock, Philip E. and Cunningham, William A.},
	month = jun,
	year = {2023},
	note = {Publisher: American Association for the Advancement of Science},
	pages = {1108--1109},
	file = {Full Text PDF:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/RMIHBU27/Grossmann et al. - 2023 - AI and the transformation of social science resear.pdf:application/pdf},
}

@article{dentella_systematic_2023,
	title = {Systematic testing of three {Language} {Models} reveals low language accuracy, absence of response stability, and a yes-response bias},
	volume = {120},
	url = {https://www.pnas.org/doi/10.1073/pnas.2309583120},
	doi = {10.1073/pnas.2309583120},
	abstract = {Humans are universally good in providing stable and accurate judgments about what forms part of their language and what not. Large Language Models (LMs) are claimed to possess human-like language abilities; hence, they are expected to emulate this behavior by providing both stable and accurate answers, when asked whether a string of words complies with or deviates from their next-word predictions. This work tests whether stability and accuracy are showcased by GPT-3/text-davinci-002, GPT-3/text-davinci-003, and ChatGPT, using a series of judgment tasks that tap on 8 linguistic phenomena: plural attraction, anaphora, center embedding, comparatives, intrusive resumption, negative polarity items, order of adjectives, and order of adverbs. For every phenomenon, 10 sentences (5 grammatical and 5 ungrammatical) are tested, each randomly repeated 10 times, totaling 800 elicited judgments per LM (total n = 2,400). Our results reveal variable above-chance accuracy in the grammatical condition, below-chance accuracy in the ungrammatical condition, a significant instability of answers across phenomena, and a yes-response bias for all the tested LMs. Furthermore, we found no evidence that repetition aids the Models to converge on a processing strategy that culminates in stable answers, either accurate or inaccurate. We demonstrate that the LMs’ performance in identifying (un)grammatical word patterns is in stark contrast to what is observed in humans (n = 80, tested on the same tasks) and argue that adopting LMs as theories of human language is not motivated at their current stage of development.},
	number = {51},
	urldate = {2023-12-19},
	journal = {Proceedings of the National Academy of Sciences},
	author = {Dentella, Vittoria and Günther, Fritz and Leivada, Evelina},
	month = dec,
	year = {2023},
	note = {Publisher: Proceedings of the National Academy of Sciences},
	pages = {e2309583120},
	file = {Full Text PDF:/Users/davidbroska/Library/Mobile Documents/com~apple~CloudDocs/Zotero/storage/6ZGK2BMZ/Dentella et al. - 2023 - Systematic testing of three Language Models reveal.pdf:application/pdf},
}
@article{rubin1974estimating,
  title={Estimating causal effects of treatments in randomized and nonrandomized studies.},
  author={Rubin, Donald B},
  journal={Journal of educational Psychology},
  volume={66},
  number={5},
  pages={688},
  year={1974},
  publisher={American Psychological Association}
}
@article{rubin2005causal,
  title={Causal inference using potential outcomes: Design, modeling, decisions},
  author={Rubin, Donald B},
  journal={Journal of the American Statistical Association},
  volume={100},
  number={469},
  pages={322--331},
  year={2005},
  publisher={Taylor \& Francis}
}
@misc{crockett_messeri_2023,
 title={Should large language models replace human participants?},
 url={osf.io/preprints/psyarxiv/4zdx9},
 DOI={10.31234/osf.io/4zdx9},
 publisher={PsyArXiv},
 author={Crockett, Molly and Messeri, Lisa},
 year={2023},
 month={Jun}
}
@misc{atari_xue_park_blasi_henrich_2023,
 title={Which Humans?},
 url={osf.io/preprints/psyarxiv/5b26t},
 DOI={10.31234/osf.io/5b26t},
 publisher={PsyArXiv},
 author={Atari, Mohammad and Xue, Mona J. and Park, Peter S. and Blasi, Damián E. and Henrich, Joseph},
 year={2023},
 month={Sep}
}

@article{breiman2001statistical,
  title={Statistical modeling: The two cultures (with comments and a rejoinder by the author)},
  author={Breiman, Leo},
  journal={Statistical science},
  volume={16},
  number={3},
  pages={199--231},
  year={2001},
  publisher={Institute of Mathematical Statistics}
}

@techreport{horton2023large,
  title={Large language models as simulated economic agents: What can we learn from homo silicus?},
  author={Horton, John J},
  year={2023},
  institution={National Bureau of Economic Research}
}


@article{tjuatja2023llms,
  title={Do llms exhibit human-like response biases? a case study in survey design},
  author={Tjuatja, Lindia and Chen, Valerie and Wu, Sherry Tongshuang and Talwalkar, Ameet and Neubig, Graham},
  journal={arXiv preprint arXiv:2311.04076},
  year={2023}
}

@article{splawa1990application,
  title={On the application of probability theory to agricultural experiments. Essay on principles. Section 9.},
  author={Splawa-Neyman, Jerzy and Dabrowska, Dorota M and Speed, Terrence P},
  journal={Statistical Science},
  pages={465--472},
  year={1990},
  publisher={JSTOR}
}

@article{holland1986statistics,
  title={Statistics and causal inference},
  author={Holland, Paul W},
  journal={Journal of the American statistical Association},
  volume={81},
  number={396},
  pages={945--960},
  year={1986},
  publisher={Taylor \& Francis}
}

@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{van2022three,
  title={Three families of automated text analysis},
  author={van Loon, Austin},
  journal={Social Science Research},
  volume={108},
  pages={102798},
  year={2022},
  publisher={Elsevier}
}

@inproceedings{abid2021persistent,
  title={Persistent anti-muslim bias in large language models},
  author={Abid, Abubakar and Farooqi, Maheen and Zou, James},
  booktitle={Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society},
  pages={298--306},
  year={2021}
}

@article{navigli2023biases,
  title={Biases in large language models: origins, inventory, and discussion},
  author={Navigli, Roberto and Conia, Simone and Ross, Bj{\"o}rn},
  journal={ACM Journal of Data and Information Quality},
  volume={15},
  number={2},
  pages={1--21},
  year={2023},
  publisher={ACM New York, NY}
}

@article{tornberg2023simulating,
  title={Simulating social media using large language models to evaluate alternative news feed algorithms},
  author={T{\"o}rnberg, Petter and Valeeva, Diliara and Uitermark, Justus and Bail, Christopher},
  journal={arXiv preprint arXiv:2310.05984},
  year={2023}
}

@article{dillion2023can,
  title={Can AI language models replace human participants?},
  author={Dillion, Danica and Tandon, Niket and Gu, Yuling and Gray, Kurt},
  journal={Trends in Cognitive Sciences},
  year={2023},
  publisher={Elsevier}
}


@misc{MungerLifeItself,
  title = {I strongly feel that this is an insult to life itself: The goal of social science cannot be to eliminate humans},
  howpublished = {\url{https://kevinmunger.substack.com/p/i-strongly-feel-that-this-is-an-insult}},
  note = {Accessed: 2024-03-24},
  author={Munger, Kevin},
  year={2023}
}

@article{agnew2024illusion,
  title={The illusion of artificial inclusion},
  author={Agnew, William and Bergman, A Stevie and Chien, Jennifer and D{\'\i}az, Mark and El-Sayed, Seliem and Pittman, Jaylen and Mohamed, Shakir and McKee, Kevin R},
  journal={arXiv preprint arXiv:2401.08572},
  year={2024}
}

@article{harding2023ai,
  title={AI language models cannot replace human research participants},
  author={Harding, Jacqueline and D’Alessandro, William and Laskowski, NG and Long, Robert},
  journal={Ai \& Society},
  pages={1--3},
  year={2023},
  publisher={Springer}
}

@article{wang2024large,
  title={Large language models cannot replace human participants because they cannot portray identity groups},
  author={Wang, Angelina and Morgenstern, Jamie and Dickerson, John P},
  journal={arXiv preprint arXiv:2402.01908},
  year={2024}
}
@article{binz2024using,
author = {Marcel Binz  and Eric Schulz },
title = {Using cognitive psychology to understand GPT-3},
journal = {Proceedings of the National Academy of Sciences},
volume = {120},
number = {6},
year = {2023},
doi = {10.1073/pnas.2218523120},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.2218523120},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.2218523120},
abstract = {We study GPT-3, a recent large language model, using tools from cognitive psychology. More specifically, we assess GPT-3’s decision-making, information search, deliberation, and causal reasoning abilities on a battery of canonical experiments from the literature. We find that much of GPT-3’s behavior is impressive: It solves vignette-based tasks similarly or better than human subjects, is able to make decent decisions from descriptions, outperforms humans in a multiarmed bandit task, and shows signatures of model-based reinforcement learning. Yet, we also find that small perturbations to vignette-based tasks can lead GPT-3 vastly astray, that it shows no signatures of directed exploration, and that it fails miserably in a causal reasoning task. Taken together, these results enrich our understanding of current large language models and pave the way for future investigations using tools from cognitive psychology to study increasingly capable and opaque artificial agents.}}

