{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from ppi_py import ppi_ols_ci, classical_ols_ci, ppi_ols_pointestimate\n",
    "\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/davidbroska/IntegrativeExperimentsGAI/main/Data/5_SurveySampleLLM.csv.gz\")\n",
    "df = pd.read_csv(\"../Data/5_SurveySampleLLM.csv.gz\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Covs = ['PedPed', 'Barrier', 'CrossingSignal', 'NumberOfCharacters',\n",
    "        'DiffNumberOFCharacters', 'LeftHand', 'Man', 'Woman', 'Pregnant',\n",
    "        'Stroller', 'OldMan', 'OldWoman', 'Boy', 'Girl', 'Homeless',\n",
    "        'LargeWoman', 'LargeMan', 'Criminal', 'MaleExecutive',\n",
    "        'FemaleExecutive', 'FemaleAthlete', 'MaleAthlete', 'FemaleDoctor',\n",
    "        'MaleDoctor', 'Dog', 'Cat', \n",
    "        'Intervention'\n",
    "        ]\n",
    "\n",
    "def calc_ci(df, x, y, n, N):\n",
    "  \"\"\"\n",
    "  Args:\n",
    "      df: DataFrame containing the variables listed below\n",
    "      x:  The name of the predictor variable (e.g. Barrier, Dog,...).\n",
    "      y:  The name of the dependent variable\n",
    "      n:  The sample size of the human responses.\n",
    "      N:  The sample size of the responses predicted by the algorithm.\n",
    "\n",
    "  Returns:\n",
    "      A DataFrame with the following columns:\n",
    "        x: The name of the predictor variable.\n",
    "        n: The sample size.\n",
    "        N: The population size.\n",
    "        lower_CI_ppi: The lower bound of the PPI confidence interval.\n",
    "        upper_CI_ppi: The upper bound of the PPI confidence interval.\n",
    "        lower_CI_ols: The lower bound of the OLS confidence interval.\n",
    "        upper_CI_ols: The upper bound of the OLS confidence interval.\n",
    "  \"\"\"\n",
    "\n",
    "  sub_df = df.sample(n+N, ignore_index=True)\n",
    "\n",
    "  # ensure that there is variation in X and Y in the sample \n",
    "  ncats = sub_df.groupby([x,'Saved']).count().shape[0]\n",
    "  ncatsLLM = sub_df.groupby([x,'Saved']).count().shape[0]\n",
    "\n",
    "  # in the rare when there is no variation, sample again (4 bc there are two variables with two levels)\n",
    "  while(ncats < 4 or ncatsLLM < 4):\n",
    "    sub_df = df.sample(n+N, ignore_index=True)\n",
    "    ncats = sub_df.groupby([x,'Saved']).count().shape[0]\n",
    "    ncatsLLM = sub_df.groupby([x,'Saved']).count().shape[0]\n",
    "\n",
    "  df_people = sub_df.iloc[:n]\n",
    "  df_gpt = sub_df.iloc[n:]\n",
    "\n",
    "  Xn = np.ones((n,2))                            # intercept\n",
    "  Xn[:,1] = df_people[x]                         # covariates in the labeled data\n",
    "  Yn_ppl = df_people['Saved'].to_numpy()         # observed outcomes\n",
    "  Yn_gpt = df_people[y].to_numpy()               # LLM predictions for labeled data\n",
    "  w_labeled = df_people['weights'].to_numpy()    # define weigths for the labeled data\n",
    "\n",
    "  XN = np.ones((N,2))\n",
    "  XN[:,1] = df_gpt[x]\n",
    "  YN_gpt = df_gpt[y].to_numpy()\n",
    "  w_unlabeled = df_gpt['weights'].to_numpy()\n",
    "\n",
    "  # calculate point estimate\n",
    "  pointest_ppi = ppi_ols_pointestimate(Xn, Yn_ppl, Yn_gpt, XN, YN_gpt, w=w_labeled, w_unlabeled=w_unlabeled)\n",
    "\n",
    "  # calculate confidence intervals\n",
    "  # https://ppi-py.readthedocs.io/en/latest/baselines.html#ppi_py.classical_ols_ci\n",
    "  lower_CI_ppi, upper_CI_ppi = ppi_ols_ci(Xn, Yn_ppl, Yn_gpt, XN, YN_gpt, w=w_labeled, w_unlabeled=w_unlabeled,alpha=.05)\n",
    "  lower_CI_ols, upper_CI_ols = classical_ols_ci(Xn, Yn_ppl, w=w_labeled,alpha=.05)\n",
    "\n",
    "  # Create and return the output DataFrame\n",
    "  output_df = pd.DataFrame({\n",
    "      \"y\": y,\n",
    "      \"x\": x,\n",
    "      \"n\": n,\n",
    "      \"N\": N,\n",
    "      \"pointest_ppi\": pointest_ppi[1],\n",
    "      \"lower_CI_ppi\": lower_CI_ppi[1],\n",
    "      \"upper_CI_ppi\": upper_CI_ppi[1],\n",
    "      \"lower_CI_ols\": lower_CI_ols[1],\n",
    "      \"upper_CI_ols\": upper_CI_ols[1]}, index=[0])\n",
    "  return output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating over dependent variable: gpt35turbo0125_wp_Saved\n",
      "    Predictor: NumberOfCharacters\n",
      "    Predictor: Boy\n",
      "    Predictor: Girl\n",
      "    Predictor: Woman\n",
      "    Predictor: Man\n",
      "Iterating over dependent variable: gpt4turbo_wp_Saved\n",
      "    Predictor: NumberOfCharacters\n",
      "    Predictor: Boy\n",
      "    Predictor: Girl\n",
      "    Predictor: Woman\n",
      "    Predictor: Man\n",
      "Iterating over dependent variable: gpt4o_wp_Saved\n",
      "    Predictor: NumberOfCharacters\n",
      "    Predictor: Boy\n",
      "    Predictor: Girl\n",
      "    Predictor: Woman\n",
      "    Predictor: Man\n"
     ]
    }
   ],
   "source": [
    "ns = range(50,250,50)\n",
    "ks = range(1,11,1)\n",
    "Ys = [\"gpt35turbo0125_wp_Saved\",\"gpt4turbo_wp_Saved\",\"gpt4o_wp_Saved\"]#,\n",
    "      #\"gpt35turbo0125_np_Saved\",\"gpt4turbo_np_Saved\",\"gpt4o_np_Saved\"]\n",
    "Xs = ['NumberOfCharacters','Boy','Girl','Woman','Man']\n",
    "reps = 10\n",
    "result = pd.DataFrame()\n",
    "for y in Ys: \n",
    "  print(f\"Iterating over dependent variable: {y}\")\n",
    "\n",
    "  for x in Xs:\n",
    "    print(f\"    Predictor: {x}\")\n",
    "\n",
    "    for n in ns:\n",
    "      #print(f\"with human sample size: {n}\")\n",
    "\n",
    "      for k in ks:\n",
    "        N = n*k\n",
    "        #print(f\"Iterating over the LLM sample size: {N}\")\n",
    "\n",
    "        for r in range(reps):\n",
    "          result = pd.concat([result, calc_ci(df=df,x=x, y=y, n=n, N=N)],ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(\"../Data/6_ResultsPPI.csv.gz\", compression=\"gzip\", index=False)\n",
    "df = pd.read_csv(\"../Data/6_ResultsPPI.csv.gz\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
