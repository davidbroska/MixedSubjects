{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup\n",
    "\n",
    "In this section, we load necessary libraries and define custom functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install PPI library if needed \n",
    "# %pip install git+https://github.com/Michael-Howes/ppi_py.git\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.11.4 (v3.11.4:d2340ef257, Jun  6 2023, 19:15:51) [Clang 13.0.0 (clang-1300.0.29.30)]'"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import statsmodels.api as sm\n",
    "import sys\n",
    "from scipy import stats\n",
    "from ppi_py import ppi_ols_ci, classical_ols_ci, ppi_ols_pointestimate\n",
    "\n",
    "df = pd.read_csv(\"../Data/5_SurveySampleLLM.csv.gz\")\n",
    "\n",
    "Covs = ['PedPed', 'Barrier', 'CrossingSignal', 'NumberOfCharacters',\n",
    "        'DiffNumberOFCharacters', 'LeftHand', 'Man', 'Woman', 'Pregnant',\n",
    "        'Stroller', 'OldMan', 'OldWoman', 'Boy', 'Girl', 'Homeless',\n",
    "        'LargeWoman', 'LargeMan', 'Criminal', 'MaleExecutive',\n",
    "        'FemaleExecutive', 'FemaleAthlete', 'MaleAthlete', 'FemaleDoctor',\n",
    "        'MaleDoctor', 'Dog', 'Cat', \n",
    "        'Intervention'\n",
    "        ]\n",
    "\n",
    "sys.version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of respondents:  2097\n",
      "Number of decisions:  22315\n",
      "Number of NAs in observed dependent variable:  0\n",
      "Number of NAs in predicted dependent variable with o1 Mini:  35124\n",
      "Number of NAs in predicted dependent variable with o1 Preview:  50548\n",
      "Number of NAs in predicted dependent variable with GPT4 Turbo:  6086\n",
      "Number of NAs in predicted dependent variable with GPT4o:  6092\n",
      "Number of NAs in predicted dependent variable with GPT3.5 Turbo:  6088\n",
      "Number of NAs in predicted dependent variable with Claude 3.5 Sonnet:  37540\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of respondents: \", len(df[\"UserID\"].unique()))\n",
    "print(\"Number of decisions: \", len(df[\"ResponseID\"].unique()))\n",
    "print(\"Number of NAs in observed dependent variable: \", df[\"Saved\"].isna().sum())\n",
    "print(\"Number of NAs in predicted dependent variable with o1 Mini: \", df[\"o1mini_wp_Saved_1\"].isna().sum())\n",
    "print(\"Number of NAs in predicted dependent variable with o1 Preview: \", df[\"o1preview_wp_Saved_1\"].isna().sum())\n",
    "print(\"Number of NAs in predicted dependent variable with GPT4 Turbo: \", df[\"gpt4turbo_wp_Saved_1\"].isna().sum())\n",
    "print(\"Number of NAs in predicted dependent variable with GPT4o: \", df[\"gpt4o_wp_Saved_1\"].isna().sum())\n",
    "print(\"Number of NAs in predicted dependent variable with GPT3.5 Turbo: \", df[\"gpt35turbo0125_wp_Saved_1\"].isna().sum())\n",
    "print(\"Number of NAs in predicted dependent variable with Claude 3.5 Sonnet: \", df[\"claude35sonnet20241022_wp_Saved_1\"].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproduce AMCE from R functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awad et al. (2018) use R to estimate the AMCE for the the conjoint experiment. In this section, we verify that we can obtain the results with our Python code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CalcTheoreticalInt(r):\n",
    "    # this function is applied to each row (r)\n",
    "    if r[\"Intervention\"]==0:\n",
    "        if r[\"Barrier\"]==0:\n",
    "            if r[\"PedPed\"]==1: p = 0.48\n",
    "            else: p = 0.32\n",
    "            \n",
    "            if r[\"CrossingSignal\"]==0:   p = p * 0.48\n",
    "            elif r[\"CrossingSignal\"]==1: p = p * 0.2\n",
    "            else: p = p * 0.32\n",
    "        else: p = 0.2\n",
    "\n",
    "    else: \n",
    "        if r[\"Barrier\"]==0:\n",
    "            if r[\"PedPed\"]==1: \n",
    "                p = 0.48\n",
    "                if r[\"CrossingSignal\"]==0: p = p * 0.48\n",
    "                elif r[\"CrossingSignal\"]==1: p = p * 0.32\n",
    "                else: p = p * 0.2\n",
    "            else: \n",
    "                p = 0.2\n",
    "                if r[\"CrossingSignal\"]==0: p = p * 0.48\n",
    "                elif r[\"CrossingSignal\"]==1: p = p * 0.2\n",
    "                else: p = p * 0.32\n",
    "        else: p = 0.32  \n",
    "    \n",
    "    return(p)  \n",
    "        \n",
    "def calcWeightsTheoretical(profiles):\n",
    "    \n",
    "    p = profiles.apply(CalcTheoreticalInt, axis=1)\n",
    "\n",
    "    weight = 1/p \n",
    "\n",
    "    return(weight)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function from PPI to calculate stats\n",
    "def _ols_get_stats(\n",
    "    pointest,\n",
    "    X,\n",
    "    Y,\n",
    "    Yhat,\n",
    "    X_unlabeled,\n",
    "    Yhat_unlabeled,\n",
    "    w=None,\n",
    "    w_unlabeled=None,\n",
    "    use_unlabeled=True,\n",
    "):\n",
    "    \"\"\"Computes the statistics needed for the OLS-based prediction-powered inference.\n",
    "\n",
    "    Args:\n",
    "        pointest (ndarray): A point estimate of the coefficients.\n",
    "        X (ndarray): Covariates for the labeled data set.\n",
    "        Y (ndarray): Labels for the labeled data set.\n",
    "        Yhat (ndarray): Predictions for the labeled data set.\n",
    "        X_unlabeled (ndarray): Covariates for the unlabeled data set.\n",
    "        Yhat_unlabeled (ndarray): Predictions for the unlabeled data set.\n",
    "        w (ndarray, optional): Sample weights for the labeled data set.\n",
    "        w_unlabeled (ndarray, optional): Sample weights for the unlabeled data set.\n",
    "        use_unlabeled (bool, optional): Whether to use the unlabeled data set.\n",
    "\n",
    "    Returns:\n",
    "        grads (ndarray): Gradient of the loss function with respect to the coefficients.\n",
    "        grads_hat (ndarray): Gradient of the loss function with respect to the coefficients, evaluated using the labeled predictions.\n",
    "        grads_hat_unlabeled (ndarray): Gradient of the loss function with respect to the coefficients, evaluated using the unlabeled predictions.\n",
    "        inv_hessian (ndarray): Inverse Hessian of the loss function with respect to the coefficients.\n",
    "    \"\"\"\n",
    "    n = Y.shape[0]\n",
    "    N = Yhat_unlabeled.shape[0]\n",
    "    d = X.shape[1]\n",
    "    w = np.ones(n) if w is None else w / np.sum(w) * n\n",
    "    w_unlabeled = (\n",
    "        np.ones(N)\n",
    "        if w_unlabeled is None\n",
    "        else w_unlabeled / np.sum(w_unlabeled) * N\n",
    "    )\n",
    "\n",
    "    hessian = np.zeros((d, d))\n",
    "    grads_hat_unlabeled = np.zeros(X_unlabeled.shape)\n",
    "    if use_unlabeled:\n",
    "        for i in range(N):\n",
    "            hessian += (\n",
    "                w_unlabeled[i]\n",
    "                / (N + n)\n",
    "                * np.outer(X_unlabeled[i], X_unlabeled[i])\n",
    "            )\n",
    "            grads_hat_unlabeled[i, :] = (\n",
    "                w_unlabeled[i]\n",
    "                * X_unlabeled[i, :]\n",
    "                * (np.dot(X_unlabeled[i, :], pointest) - Yhat_unlabeled[i])\n",
    "            )\n",
    "\n",
    "    grads = np.zeros(X.shape)\n",
    "    grads_hat = np.zeros(X.shape)\n",
    "    for i in range(n):\n",
    "        hessian += (\n",
    "            w[i] / (N + n) * np.outer(X[i], X[i])\n",
    "            if use_unlabeled\n",
    "            else w[i] / n * np.outer(X[i], X[i])\n",
    "        )\n",
    "        grads[i, :] = w[i] * X[i, :] * (np.dot(X[i, :], pointest) - Y[i])\n",
    "        grads_hat[i, :] = (\n",
    "            w[i] * X[i, :] * (np.dot(X[i, :], pointest) - Yhat[i])\n",
    "        )\n",
    "\n",
    "    inv_hessian = np.linalg.inv(hessian).reshape(d, d)\n",
    "    return grads, grads_hat, grads_hat_unlabeled, inv_hessian\n",
    "\n",
    "def _power_analysis_stats(grads, grads_hat, inv_hessian):\n",
    "    grads_ = grads - grads.mean(axis=0)\n",
    "    grads_hat_ = grads_hat - grads_hat.mean(axis=0)\n",
    "    cov = inv_hessian @ (grads_[:,None,:] * grads_hat_[:,:,None]).mean(axis=0) @ inv_hessian\n",
    "    var = inv_hessian @ (grads_[:,None,:]*grads_[:,:,None]).mean(axis=0) @ inv_hessian\n",
    "    var_hat = inv_hessian @ (grads_hat_[:,None,:]*grads_hat_[:,:,None]).mean(axis=0) @ inv_hessian\n",
    "    rhos = np.diag(cov)/np.sqrt((np.diag(var)*np.diag(var_hat)))\n",
    "    sigmas_sq = np.diag(var)\n",
    "    return rhos, sigmas_sq\n",
    "\n",
    "def _estimate_ppi_SE(n, N, rho_sq, var_Y):\n",
    "    if N == np.inf:\n",
    "        return np.sqrt(var_Y*(1-rho_sq)/n)\n",
    "    if N == 0:\n",
    "        return np.sqrt(var_Y/n)\n",
    "    var_ppi = var_Y*(1-rho_sq*N/(n+N))/n\n",
    "    return np.sqrt(var_ppi)\n",
    "\n",
    "def _estimate_classical_SE(n, var_Y):\n",
    "    return np.sqrt(var_Y/n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we define a function to compute the Average Marginal Component Effect (AMCE) for an attribute of the moral dilemmas using  weighted least squares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amce(data, x, y, alpha=0.05):\n",
    "\n",
    "    # specify regression for swerve or stay in lane\n",
    "    if x==\"Intervention\":\n",
    "        \n",
    "        # calculate weights\n",
    "        data.loc[:,\"weights\"] = calcWeightsTheoretical(data)\n",
    "    \n",
    "        # drop rows with missing values on dependent variable\n",
    "        dd = data.dropna(subset=y)\n",
    "\n",
    "        # if X=1 characters die if AV serves, if X=0 characters if AV stays\n",
    "        X = dd[\"Intervention\"]\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # define model with standard errors clustered on UserID\n",
    "        model = sm.WLS(dd[y], X, weights=dd[\"weights\"])\n",
    "    \n",
    "\n",
    "    # specify regression for relationship to vehicle\n",
    "    if x==\"Barrier\":\n",
    "\n",
    "        # consider only dilemmas without legality and only pedestrians vs passengers\n",
    "        data_sub = data.loc[(data[\"CrossingSignal\"]==0) & (data[\"PedPed\"]==0), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        dd = data_sub.dropna(subset=y)\n",
    "        \n",
    "        # if X=1 passengers die and if X=0 pedestrians die\n",
    "        X = dd[\"Barrier\"]\n",
    "\n",
    "        # recode to estimate the preference for pedestrians over passengers \n",
    "        X = 1 - X\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # define model with standard errors clustered on UserID\n",
    "        model = sm.WLS(dd[y], X, weights=dd[\"weights\"])\n",
    "\n",
    "    \n",
    "    # specify regression for legality\n",
    "    if x==\"CrossingSignal\": \n",
    "        \n",
    "        # consider dilemmas with legality and only pedestrians vs pedestrians\n",
    "        data_sub = data.loc[(data[\"CrossingSignal\"]!=0) & (data[\"PedPed\"]==1), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        dd = data_sub.dropna(subset=y)\n",
    "\n",
    "        # if X=1 pedestrians cross on a green light, if X=2 pedestrians cross on a red light \n",
    "        X = dd[\"CrossingSignal\"]\n",
    "\n",
    "        # create dummy variable to estimate preference for pedestrians that cross legally (1) vs legally (0)\n",
    "        X = 2 - X \n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # define model with standard errors clustered on UserID\n",
    "        model = sm.WLS(dd[y], X, weights=dd[\"weights\"])\n",
    "\n",
    "    \n",
    "\n",
    "    # Specify regressions for the remaining six attributes\n",
    "    if x==\"Utilitarian\":\n",
    "        \n",
    "        # consider dilemmas that compare 'More' versus 'Less' characters\n",
    "        data_sub = data.loc[(data[\"ScenarioType\"]==\"Utilitarian\") & (data[\"ScenarioTypeStrict\"]==\"Utilitarian\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        dd = data_sub.dropna(subset=y)\n",
    "        dd = dd.rename(columns = {'AttributeLevel': 'Utilitarian'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing more characters\n",
    "        X = (dd.loc[:,\"Utilitarian\"]==\"More\").astype(int)\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # define model with standard errors clustered on UserID\n",
    "        model = sm.WLS(dd[y], X, weights=dd[\"weights\"])\n",
    "\n",
    "\n",
    "    if x==\"Species\":\n",
    "        \n",
    "        # consider dilemmas that compare humans versus animals \n",
    "        data_sub = data.loc[(data[\"ScenarioType\"]==\"Species\") & (data[\"ScenarioTypeStrict\"]==\"Species\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        dd = data_sub.dropna(subset=y)\n",
    "        dd = dd.rename(columns = {'AttributeLevel': 'Species'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing humans\n",
    "        X = (dd.loc[:,\"Species\"]==\"Hoomans\").astype(int)\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # define model with standard errors clustered on UserID\n",
    "        model = sm.WLS(dd[y], X, weights=dd[\"weights\"])\n",
    "    \n",
    "\n",
    "    if x==\"Gender\":\n",
    "        \n",
    "        # consider dilemmas that compare women versus men\n",
    "        data_sub = data.loc[(data[\"ScenarioType\"]==\"Gender\") & (data[\"ScenarioTypeStrict\"]==\"Gender\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        dd = data_sub.dropna(subset=y)\n",
    "        dd = dd.rename(columns = {'AttributeLevel': 'Gender'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing women\n",
    "        X = (dd.loc[:,\"Gender\"]==\"Female\").astype(int)\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # define model with standard errors clustered on UserID\n",
    "        model = sm.WLS(dd[y], X, weights=dd[\"weights\"])\n",
    "\n",
    "\n",
    "    if x==\"Fitness\":\n",
    "        \n",
    "        # consider dilemmas that compare fit characters versus those that are not\n",
    "        data_sub = data.loc[(data[\"ScenarioType\"]==\"Fitness\") & (data[\"ScenarioTypeStrict\"]==\"Fitness\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        dd = data_sub.dropna(subset=y)\n",
    "        dd = dd.rename(columns = {'AttributeLevel': 'Fitness'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing fit characters\n",
    "        X = (dd.loc[:,\"Fitness\"]==\"Fit\").astype(int)\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # define model with standard errors clustered on UserID\n",
    "        model = sm.WLS(dd[y], X, weights=dd[\"weights\"])\n",
    "\n",
    "\n",
    "    if x==\"Age\":\n",
    "        \n",
    "        # consider dilemmas that compare younger versus older characters\n",
    "        data_sub = data.loc[(data[\"ScenarioType\"]==\"Age\") & (data[\"ScenarioTypeStrict\"]==\"Age\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        dd = data_sub.dropna(subset=y)\n",
    "        dd = dd.rename(columns = {'AttributeLevel': 'Age'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing younger characters\n",
    "        X = (dd.loc[:,\"Age\"]==\"Young\").astype(int)\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # define model with standard errors clustered on UserID\n",
    "        model = sm.WLS(dd[y], X, weights=dd[\"weights\"])\n",
    "\n",
    "    \n",
    "    if x==\"Social Status\":\n",
    "        \n",
    "        # consider dilemmas that compare high status versus low status characters\n",
    "        data_sub = data.loc[(data[\"ScenarioType\"]==\"Social Status\") & (data[\"ScenarioTypeStrict\"]==\"Social Status\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        dd = data_sub.dropna(subset=y)\n",
    "        dd = dd.rename(columns = {'AttributeLevel': 'Social Status'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing high status characters\n",
    "        X = (dd.loc[:,\"Social Status\"]==\"High\").astype(int)\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "        # define model with standard errors clustered on UserID\n",
    "        model = sm.WLS(dd[y], X, weights=dd[\"weights\"])\n",
    "\n",
    "\n",
    "\n",
    "    # fit model and extract estimates\n",
    "    fit = model.fit(cov_type = 'cluster', cov_kwds = {'groups': dd[\"UserID\"]})\n",
    "    coef = fit.params[x]\n",
    "    se = fit.bse[x]\n",
    "    ci = fit.conf_int(alpha=alpha).loc[x]\n",
    "\n",
    "    # store results\n",
    "    res = pd.DataFrame({\n",
    "        'x': [x],\n",
    "        'y': [y],\n",
    "        'beta': [coef],\n",
    "        'se': [se],\n",
    "        'lower': [ci[0]],\n",
    "        'upper': [ci[1]]\n",
    "    })\n",
    "\n",
    "    return(res)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we compute the AMCEs only with data from human subjects using the functions defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>beta</th>\n",
       "      <th>se</th>\n",
       "      <th>lower</th>\n",
       "      <th>upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Intervention</td>\n",
       "      <td>Saved</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Barrier</td>\n",
       "      <td>Saved</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gender</td>\n",
       "      <td>Saved</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.121</td>\n",
       "      <td>0.189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fitness</td>\n",
       "      <td>Saved</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.019</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Social Status</td>\n",
       "      <td>Saved</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.049</td>\n",
       "      <td>0.071</td>\n",
       "      <td>0.265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CrossingSignal</td>\n",
       "      <td>Saved</td>\n",
       "      <td>0.339</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.309</td>\n",
       "      <td>0.370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Age</td>\n",
       "      <td>Saved</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.463</td>\n",
       "      <td>0.526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>Saved</td>\n",
       "      <td>0.575</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Species</td>\n",
       "      <td>Saved</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.601</td>\n",
       "      <td>0.664</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                x      y   beta     se  lower  upper\n",
       "0    Intervention  Saved  0.065  0.008  0.049  0.082\n",
       "0         Barrier  Saved  0.150  0.015  0.121  0.179\n",
       "0          Gender  Saved  0.155  0.017  0.121  0.189\n",
       "0         Fitness  Saved  0.130  0.019  0.094  0.167\n",
       "0   Social Status  Saved  0.168  0.049  0.071  0.265\n",
       "0  CrossingSignal  Saved  0.339  0.016  0.309  0.370\n",
       "0             Age  Saved  0.494  0.016  0.463  0.526\n",
       "0     Utilitarian  Saved  0.575  0.015  0.546  0.604\n",
       "0         Species  Saved  0.632  0.016  0.601  0.664"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amce_human_subjects = pd.concat([\n",
    "    compute_amce(df, x=\"Intervention\", y=\"Saved\"), \n",
    "    compute_amce(df, x=\"Barrier\", y=\"Saved\"), \n",
    "    compute_amce(df, x=\"Gender\", y=\"Saved\"), \n",
    "    compute_amce(df, x=\"Fitness\", y=\"Saved\"), \n",
    "    compute_amce(df, x=\"Social Status\", y=\"Saved\"), \n",
    "    compute_amce(df, x=\"CrossingSignal\",y=\"Saved\"),\n",
    "    compute_amce(df, x=\"Age\", y=\"Saved\"),\n",
    "    compute_amce(df, x=\"Utilitarian\", y=\"Saved\"),\n",
    "    compute_amce(df, x=\"Species\", y=\"Saved\")\n",
    "])      \n",
    "amce_human_subjects.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The AMCE estimates above are the same as those calculated with the functions by Awad et al. (2018), see object `main.Saved` in the R script `8_CalculateAMCE.R`. Hence, the custom functions defined in this notebook give the same results as the functions defined in the original article. \n",
    "\n",
    "\n",
    "|           label            |    dv  |  amce |   se  | conf.low | conf.high |\n",
    "|----------------------------|--------|-------|-------|----------|-----------|\n",
    "|   Intervention             | Saved  | 0.068 | 0.008 |    0.052 |     0.084 |\n",
    "|        Barrier             | Saved  | 0.165 | 0.014 |    0.137 |     0.193 |\n",
    "|            Law             | Saved  | 0.336 | 0.015 |    0.307 |     0.366 |\n",
    "|         Gender             | Saved  | 0.160 | 0.017 |    0.127 |     0.193 |\n",
    "|        Fitness             | Saved  | 0.121 | 0.018 |    0.085 |     0.156 |\n",
    "|  Social Status             | Saved  | 0.171 | 0.047 |    0.079 |     0.263 |\n",
    "|            Age             | Saved  | 0.482 | 0.016 |    0.451 |     0.513 |\n",
    "| No. Characters             | Saved  | 0.573 | 0.014 |    0.545 |     0.602 |\n",
    "|        Species             | Saved  | 0.646 | 0.015 |    0.617 |     0.675 |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_amce_ppi(n_data, N_data, x, y, alpha=0.05):\n",
    "\n",
    "    # specify regression for swerve or stay in lane\n",
    "    if x==\"Intervention\":\n",
    "        \n",
    "        # calculate weights\n",
    "        n_data.loc[:,\"weights\"] = calcWeightsTheoretical(n_data)\n",
    "        N_data.loc[:,\"weights\"] = calcWeightsTheoretical(N_data)\n",
    "    \n",
    "        # drop rows with missing values on dependent variable\n",
    "        n_dd = n_data.dropna(subset=y)\n",
    "        N_dd = N_data.dropna(subset=y)\n",
    "\n",
    "        # if X=1 characters die if AV serves, if X=0 characters if AV stays\n",
    "        n_X = n_dd[\"Intervention\"]               \n",
    "        N_X = N_dd[\"Intervention\"]\n",
    "\n",
    "        # add intercept\n",
    "        n_X = np.column_stack((np.ones(n_X.shape[0]), n_X))\n",
    "        N_X = np.column_stack((np.ones(N_X.shape[0]), N_X))\n",
    "\n",
    "        # gold standard data\n",
    "        n_Y_human   = n_dd[\"Saved\"].to_numpy()    # observed outcomes\n",
    "        n_Y_silicon = n_dd[y].to_numpy()          # predicted outcomes\n",
    "        n_weights = n_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "        # unlabeled data\n",
    "        N_Y_silicon = N_dd[y].to_numpy()          # predicted outcomes\n",
    "        N_weights = N_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "\n",
    "\n",
    "    # specify regression for relationship to vehicle\n",
    "    if x==\"Barrier\":\n",
    "\n",
    "        # consider only dilemmas without legality and only pedestrians vs passengers\n",
    "        n_data_sub = n_data.loc[(n_data[\"CrossingSignal\"]==0) & (n_data[\"PedPed\"]==0), :].copy()\n",
    "        N_data_sub = N_data.loc[(N_data[\"CrossingSignal\"]==0) & (N_data[\"PedPed\"]==0), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        n_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(n_data_sub)\n",
    "        N_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(N_data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        n_dd = n_data_sub.dropna(subset=y)\n",
    "        N_dd = N_data_sub.dropna(subset=y)\n",
    "        \n",
    "        # if X=1 passengers die and if X=0 pedestrians die\n",
    "        n_X = n_dd[\"Barrier\"]\n",
    "        N_X = N_dd[\"Barrier\"]\n",
    "\n",
    "        # recode to estimate the preference for pedestrians over passengers \n",
    "        n_X = 1 - n_X\n",
    "        N_X = 1 - N_X\n",
    "\n",
    "        # add intercept\n",
    "        n_X = np.column_stack((np.ones(n_X.shape[0]), n_X))\n",
    "        N_X = np.column_stack((np.ones(N_X.shape[0]), N_X))\n",
    "\n",
    "        # gold standard data\n",
    "        n_Y_human   = n_dd[\"Saved\"].to_numpy()    # observed outcomes\n",
    "        n_Y_silicon = n_dd[y].to_numpy()          # predicted outcomes\n",
    "        n_weights = n_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "        # unlabeled data\n",
    "        N_Y_silicon = N_dd[y].to_numpy()          # predicted outcomes\n",
    "        N_weights = N_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "    \n",
    "\n",
    "    # specify regression for legality\n",
    "    if x==\"CrossingSignal\": \n",
    "        \n",
    "        # consider dilemmas with legality and only pedestrians vs pedestrians\n",
    "        n_data_sub = n_data.loc[(n_data[\"CrossingSignal\"]!=0) & (n_data[\"PedPed\"]==1), :].copy()\n",
    "        N_data_sub = N_data.loc[(N_data[\"CrossingSignal\"]!=0) & (N_data[\"PedPed\"]==1), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        n_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(n_data_sub)\n",
    "        N_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(N_data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        n_dd = n_data_sub.dropna(subset=y)\n",
    "        N_dd = N_data_sub.dropna(subset=y)\n",
    "\n",
    "        # if X=1 pedestrians cross on a green light, if X=2 pedestrians cross on a red light \n",
    "        n_X = n_dd[\"CrossingSignal\"]\n",
    "        N_X = N_dd[\"CrossingSignal\"]\n",
    "\n",
    "        # create dummy variable to estimate preference for pedestrians that cross legally (1) vs legally (0)\n",
    "        n_X = 2 - n_X \n",
    "        N_X = 2 - N_X \n",
    "\n",
    "        # add intercept\n",
    "        n_X = np.column_stack((np.ones(n_X.shape[0]), n_X))\n",
    "        N_X = np.column_stack((np.ones(N_X.shape[0]), N_X))\n",
    "\n",
    "        # gold standard data\n",
    "        n_Y_human   = n_dd[\"Saved\"].to_numpy()    # observed outcomes\n",
    "        n_Y_silicon = n_dd[y].to_numpy()          # predicted outcomes\n",
    "        n_weights = n_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "        # unlabeled data\n",
    "        N_Y_silicon = N_dd[y].to_numpy()          # predicted outcomes\n",
    "        N_weights = N_dd[\"weights\"].to_numpy()    # define weights\n",
    "    \n",
    "\n",
    "\n",
    "    # Specify regressions for the remaining six attributes\n",
    "    if x==\"Utilitarian\":\n",
    "        \n",
    "        # consider dilemmas that compare 'More' versus 'Less' characters\n",
    "        n_data_sub = n_data.loc[(n_data[\"ScenarioType\"]==\"Utilitarian\") & (n_data[\"ScenarioTypeStrict\"]==\"Utilitarian\"), :].copy()\n",
    "        N_data_sub = N_data.loc[(N_data[\"ScenarioType\"]==\"Utilitarian\") & (N_data[\"ScenarioTypeStrict\"]==\"Utilitarian\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        n_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(n_data_sub)\n",
    "        N_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(N_data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        n_dd = n_data_sub.dropna(subset=y)\n",
    "        N_dd = N_data_sub.dropna(subset=y)\n",
    "        \n",
    "        # rename column to extract coefficient from result\n",
    "        n_dd = n_dd.rename(columns = {'AttributeLevel': 'Utilitarian'})\n",
    "        N_dd = N_dd.rename(columns = {'AttributeLevel': 'Utilitarian'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing more characters\n",
    "        n_X = (n_dd.loc[:,\"Utilitarian\"]==\"More\").astype(int)\n",
    "        N_X = (N_dd.loc[:,\"Utilitarian\"]==\"More\").astype(int)\n",
    "\n",
    "        # add intercept\n",
    "        n_X = np.column_stack((np.ones(n_X.shape[0]), n_X))\n",
    "        N_X = np.column_stack((np.ones(N_X.shape[0]), N_X))\n",
    "\n",
    "        # gold standard data\n",
    "        n_Y_human   = n_dd[\"Saved\"].to_numpy()    # observed outcomes\n",
    "        n_Y_silicon = n_dd[y].to_numpy()          # predicted outcomes\n",
    "        n_weights = n_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "        # unlabeled data\n",
    "        N_Y_silicon = N_dd[y].to_numpy()          # predicted outcomes\n",
    "        N_weights = N_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "\n",
    "\n",
    "    if x==\"Species\":\n",
    "        \n",
    "        # consider dilemmas that compare humans versus animals \n",
    "        n_data_sub = n_data.loc[(n_data[\"ScenarioType\"]==\"Species\") & (n_data[\"ScenarioTypeStrict\"]==\"Species\"), :].copy()\n",
    "        N_data_sub = N_data.loc[(N_data[\"ScenarioType\"]==\"Species\") & (N_data[\"ScenarioTypeStrict\"]==\"Species\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        n_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(n_data_sub)\n",
    "        N_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(N_data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        n_dd = n_data_sub.dropna(subset=y)\n",
    "        N_dd = N_data_sub.dropna(subset=y)\n",
    "\n",
    "        # rename column to extract coefficient from result\n",
    "        n_dd = n_dd.rename(columns = {'AttributeLevel': 'Species'})\n",
    "        N_dd = N_dd.rename(columns = {'AttributeLevel': 'Species'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing humans\n",
    "        n_X = (n_dd.loc[:,\"Species\"]==\"Hoomans\").astype(int)\n",
    "        N_X = (N_dd.loc[:,\"Species\"]==\"Hoomans\").astype(int)\n",
    "\n",
    "        # add intercept\n",
    "        n_X = np.column_stack((np.ones(n_X.shape[0]), n_X))\n",
    "        N_X = np.column_stack((np.ones(N_X.shape[0]), N_X))\n",
    "\n",
    "        # gold standard data\n",
    "        n_Y_human   = n_dd[\"Saved\"].to_numpy()    # observed outcomes\n",
    "        n_Y_silicon = n_dd[y].to_numpy()          # predicted outcomes\n",
    "        n_weights = n_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "        # unlabeled data\n",
    "        N_Y_silicon = N_dd[y].to_numpy()          # predicted outcomes\n",
    "        N_weights = N_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "    \n",
    "\n",
    "    if x==\"Gender\":\n",
    "        \n",
    "        # consider dilemmas that compare women versus men\n",
    "        n_data_sub = n_data.loc[(n_data[\"ScenarioType\"]==\"Gender\") & (n_data[\"ScenarioTypeStrict\"]==\"Gender\"), :].copy()\n",
    "        N_data_sub = N_data.loc[(N_data[\"ScenarioType\"]==\"Gender\") & (N_data[\"ScenarioTypeStrict\"]==\"Gender\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        n_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(n_data_sub)\n",
    "        N_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(N_data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        n_dd = n_data_sub.dropna(subset=y)\n",
    "        N_dd = N_data_sub.dropna(subset=y)\n",
    "\n",
    "        # rename column to extract coefficient from result\n",
    "        n_dd = n_dd.rename(columns = {'AttributeLevel': 'Gender'})\n",
    "        N_dd = N_dd.rename(columns = {'AttributeLevel': 'Gender'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing women\n",
    "        n_X = (n_dd.loc[:,\"Gender\"]==\"Female\").astype(int)\n",
    "        N_X = (N_dd.loc[:,\"Gender\"]==\"Female\").astype(int)\n",
    "\n",
    "        # add intercept\n",
    "        n_X = np.column_stack((np.ones(n_X.shape[0]), n_X))\n",
    "        N_X = np.column_stack((np.ones(N_X.shape[0]), N_X))\n",
    "\n",
    "        # gold standard data\n",
    "        n_Y_human   = n_dd[\"Saved\"].to_numpy()    # observed outcomes\n",
    "        n_Y_silicon = n_dd[y].to_numpy()          # predicted outcomes\n",
    "        n_weights = n_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "        # unlabeled data\n",
    "        N_Y_silicon = N_dd[y].to_numpy()          # predicted outcomes\n",
    "        N_weights = N_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "\n",
    "\n",
    "    if x==\"Fitness\":\n",
    "        \n",
    "        # consider dilemmas that compare fit characters versus those that are not\n",
    "        n_data_sub = n_data.loc[(n_data[\"ScenarioType\"]==\"Fitness\") & (n_data[\"ScenarioTypeStrict\"]==\"Fitness\"), :].copy()\n",
    "        N_data_sub = N_data.loc[(N_data[\"ScenarioType\"]==\"Fitness\") & (N_data[\"ScenarioTypeStrict\"]==\"Fitness\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        n_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(n_data_sub)\n",
    "        N_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(N_data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        n_dd = n_data_sub.dropna(subset=y)\n",
    "        N_dd = N_data_sub.dropna(subset=y)\n",
    "\n",
    "        # rename column to extract coefficient from result\n",
    "        n_dd = n_dd.rename(columns = {'AttributeLevel': 'Fitness'})\n",
    "        N_dd = N_dd.rename(columns = {'AttributeLevel': 'Fitness'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing fit characters\n",
    "        n_X = (n_dd.loc[:,\"Fitness\"]==\"Fit\").astype(int)\n",
    "        N_X = (N_dd.loc[:,\"Fitness\"]==\"Fit\").astype(int)\n",
    "\n",
    "        # add intercept\n",
    "        n_X = np.column_stack((np.ones(n_X.shape[0]), n_X))\n",
    "        N_X = np.column_stack((np.ones(N_X.shape[0]), N_X))\n",
    "\n",
    "        # gold standard data\n",
    "        n_Y_human   = n_dd[\"Saved\"].to_numpy()    # observed outcomes\n",
    "        n_Y_silicon = n_dd[y].to_numpy()          # predicted outcomes\n",
    "        n_weights = n_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "        # unlabeled data\n",
    "        N_Y_silicon = N_dd[y].to_numpy()          # predicted outcomes\n",
    "        N_weights = N_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "\n",
    "\n",
    "    if x==\"Age\":\n",
    "        \n",
    "        # consider dilemmas that compare younger versus older characters\n",
    "        n_data_sub = n_data.loc[(n_data[\"ScenarioType\"]==\"Age\") & (n_data[\"ScenarioTypeStrict\"]==\"Age\"), :].copy()\n",
    "        N_data_sub = N_data.loc[(N_data[\"ScenarioType\"]==\"Age\") & (N_data[\"ScenarioTypeStrict\"]==\"Age\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        n_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(n_data_sub)\n",
    "        N_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(N_data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        n_dd = n_data_sub.dropna(subset=y)\n",
    "        N_dd = N_data_sub.dropna(subset=y)\n",
    "\n",
    "        # rename column to extract coefficient from result\n",
    "        n_dd = n_dd.rename(columns = {'AttributeLevel': 'Age'})\n",
    "        N_dd = N_dd.rename(columns = {'AttributeLevel': 'Age'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing younger characters\n",
    "        n_X = (n_dd.loc[:,\"Age\"]==\"Young\").astype(int)\n",
    "        N_X = (N_dd.loc[:,\"Age\"]==\"Young\").astype(int)\n",
    "\n",
    "        # add intercept\n",
    "        n_X = np.column_stack((np.ones(n_X.shape[0]), n_X))\n",
    "        N_X = np.column_stack((np.ones(N_X.shape[0]), N_X))\n",
    "\n",
    "        # gold standard data\n",
    "        n_Y_human   = n_dd[\"Saved\"].to_numpy()    # observed outcomes\n",
    "        n_Y_silicon = n_dd[y].to_numpy()          # predicted outcomes\n",
    "        n_weights = n_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "        # unlabeled data\n",
    "        N_Y_silicon = N_dd[y].to_numpy()          # predicted outcomes\n",
    "        N_weights = N_dd[\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "\n",
    "    \n",
    "    if x==\"Social Status\":\n",
    "        \n",
    "        # consider dilemmas that compare high status versus low status characters\n",
    "        n_data_sub = n_data.loc[(n_data[\"ScenarioType\"]==\"Social Status\") & (n_data[\"ScenarioTypeStrict\"]==\"Social Status\"), :].copy()\n",
    "        N_data_sub = N_data.loc[(N_data[\"ScenarioType\"]==\"Social Status\") & (N_data[\"ScenarioTypeStrict\"]==\"Social Status\"), :].copy()\n",
    "\n",
    "        # calculate weights\n",
    "        n_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(n_data_sub)\n",
    "        N_data_sub.loc[:,\"weights\"] = calcWeightsTheoretical(N_data_sub)\n",
    "\n",
    "        # drop rows with missing values on dependent variable\n",
    "        n_dd = n_data_sub.dropna(subset=y)\n",
    "        N_dd = N_data_sub.dropna(subset=y)\n",
    "\n",
    "        # rename column to extract coefficient from result\n",
    "        n_dd = n_dd.rename(columns = {'AttributeLevel': 'Social Status'})\n",
    "        N_dd = N_dd.rename(columns = {'AttributeLevel': 'Social Status'})\n",
    "\n",
    "        # create dummy variable to estimate the preference for sparing high status characters\n",
    "        n_X = (n_dd.loc[:,\"Social Status\"]==\"High\").astype(int)\n",
    "        N_X = (N_dd.loc[:,\"Social Status\"]==\"High\").astype(int)\n",
    "\n",
    "        # add intercept\n",
    "        n_X = np.column_stack((np.ones(n_X.shape[0]), n_X))\n",
    "        N_X = np.column_stack((np.ones(N_X.shape[0]), N_X))\n",
    "\n",
    "        # gold standard data\n",
    "        n_Y_human   = n_dd.loc[:,\"Saved\"].to_numpy()    # observed outcomes\n",
    "        n_Y_silicon = n_dd.loc[:,y].to_numpy()          # predicted outcomes\n",
    "        n_weights = n_dd.loc[:,\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "        # unlabeled data\n",
    "        N_Y_silicon = N_dd[y].to_numpy()                # predicted outcomes\n",
    "        N_weights = N_dd.loc[:,\"weights\"].to_numpy()    # define weights\n",
    "\n",
    "\n",
    "    # calculate point estimate\n",
    "    beta_ppi = ppi_ols_pointestimate(X=n_X, Y=n_Y_human, Yhat=n_Y_silicon, \n",
    "                                     X_unlabeled=N_X, Yhat_unlabeled=N_Y_silicon, \n",
    "                                     w=n_weights, w_unlabeled=N_weights)\n",
    "    \n",
    "    # using ppi function to calculate point estimates (lambda=0)\n",
    "    beta_hum = ppi_ols_pointestimate(X=n_X, Y=n_Y_human, Yhat=n_Y_silicon, \n",
    "                                     X_unlabeled=N_X, Yhat_unlabeled=N_Y_silicon, \n",
    "                                     w=n_weights, w_unlabeled=N_weights, \n",
    "                                     lam=0)\n",
    "    \n",
    "    beta_sil = ppi_ols_pointestimate(X=N_X, Y=N_Y_silicon, Yhat=N_Y_silicon, \n",
    "                                     X_unlabeled=N_X, Yhat_unlabeled=N_Y_silicon, \n",
    "                                     w=N_weights, w_unlabeled=N_weights, \n",
    "                                     lam=0)\n",
    "    \n",
    "    # using statsmodels to calculate point estimates (same results as with PPI)\n",
    "    beta_hum_sm = sm.WLS(endog=n_Y_human, exog=n_X, weights=n_weights).fit().params[1]\n",
    "    beta_sil_sm = sm.WLS(endog=N_Y_silicon, exog=N_X, weights=N_weights).fit().params[1]\n",
    "\n",
    "    # calculate confidence intervals for PPI, human subjects, and silicon subjects\n",
    "    lower_CI_ppi, upper_CI_ppi = ppi_ols_ci(X=n_X, Y=n_Y_human, Yhat=n_Y_silicon, \n",
    "                                            X_unlabeled=N_X, Yhat_unlabeled=N_Y_silicon, \n",
    "                                            w=n_weights, w_unlabeled=N_weights, alpha=alpha)\n",
    "    \n",
    "    lower_CI_hum, upper_CI_hum = classical_ols_ci(X=n_X, Y=n_Y_human, w=n_weights, alpha=alpha)\n",
    "\n",
    "    lower_CI_sil, upper_CI_sil = classical_ols_ci(X=N_X, Y=N_Y_silicon, w=N_weights, alpha=alpha)\n",
    "\n",
    "\n",
    "    # zscore for two tailed test\n",
    "    z = stats.norm.ppf(0.975)\n",
    "    \n",
    "    # calculate standard errors for PPI, human subjects, and silicon subjects\n",
    "    se_ppi = (upper_CI_ppi[1] - lower_CI_ppi[1]) / (2 * z)\n",
    "    \n",
    "    se_hum = (upper_CI_hum[1] - lower_CI_hum[1]) / (2 * z)\n",
    "\n",
    "    se_sil = (upper_CI_sil[1] - lower_CI_sil[1]) / (2 * z)\n",
    "    \n",
    "\n",
    "    # calculate rho\n",
    "    beta = sm.WLS(n_Y_human, n_X, weights=n_weights).fit().params\n",
    "\n",
    "    grads, grads_hat, grads_hat_unlabeled, inv_hessian = _ols_get_stats(\n",
    "        pointest=beta, \n",
    "        X=n_X,\n",
    "        Y=n_Y_human,\n",
    "        Yhat= n_Y_silicon,\n",
    "        X_unlabeled=N_X,\n",
    "        Yhat_unlabeled=N_Y_silicon,\n",
    "        w=n_weights,\n",
    "        w_unlabeled=N_weights,\n",
    "        use_unlabeled=False)\n",
    "    \n",
    "    rho, var_y = _power_analysis_stats(grads, grads_hat, inv_hessian)\n",
    "\n",
    "    # create and return the output DataFrame\n",
    "    output_df = pd.DataFrame({\n",
    "        \"y\": y,                              \n",
    "        \"x\": x,                               # Predictor variable (scenario attribute)\n",
    "        \"beta_ppi\": beta_ppi[1],              # PPI point estimate\n",
    "        \"beta_hum\": beta_hum[1],              # Human subjects point estimate\n",
    "        \"beta_hum_sm\": beta_hum_sm,           # Human subjects point estimate (statsmodels)\n",
    "        \"beta_sil\": beta_sil[1],              # Silicon subjects point estimate\n",
    "        \"beta_sil_sm\": beta_sil_sm,           # Silicon subjects point estimate (statsmodels)\n",
    "        \"se_ppi\": se_ppi,                     # PPI standard error\n",
    "        \"se_hum\": se_hum,                     # Human subjects standard error\n",
    "        \"se_sil\": se_sil,                     # Silicon subjects standard error\n",
    "        \"lower_ppi\": lower_CI_ppi[1],         # The lower bound of the PPI confidence interval\n",
    "        \"upper_ppi\": upper_CI_ppi[1],         # The upper bound of the PPI confidence interval\n",
    "        \"lower_hum\": lower_CI_hum[1],         # The lower bound of the human subjects confidence interval\n",
    "        \"upper_hum\": upper_CI_hum[1],         # The upper bound of the human subjects confidence interval\n",
    "        \"lower_sil\": lower_CI_sil[1],         # The lower bound of the silicon subjects confidence interval\n",
    "        \"upper_sil\": upper_CI_sil[1],         # The upper bound of the silicon subjects confidence interval\n",
    "        \"ppi_corr\": rho[1]},      # The association between predictions and outcomes\n",
    "        index=[0])\n",
    "    \n",
    "    return output_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model:  gpt4turbo_wp_Saved_1\n",
      "Model:  gpt4o_wp_Saved_1\n",
      "Model:  gpt35turbo0125_wp_Saved_1\n",
      "Model:  o1mini_wp_Saved_1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>beta_ppi</th>\n",
       "      <th>beta_hum</th>\n",
       "      <th>beta_hum_sm</th>\n",
       "      <th>beta_sil</th>\n",
       "      <th>beta_sil_sm</th>\n",
       "      <th>se_ppi</th>\n",
       "      <th>se_hum</th>\n",
       "      <th>se_sil</th>\n",
       "      <th>lower_ppi</th>\n",
       "      <th>upper_ppi</th>\n",
       "      <th>lower_hum</th>\n",
       "      <th>upper_hum</th>\n",
       "      <th>lower_sil</th>\n",
       "      <th>upper_sil</th>\n",
       "      <th>ppi_corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.080673</td>\n",
       "      <td>0.080648</td>\n",
       "      <td>0.080648</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>0.009471</td>\n",
       "      <td>0.009476</td>\n",
       "      <td>7.837482e-02</td>\n",
       "      <td>0.062109</td>\n",
       "      <td>0.099235</td>\n",
       "      <td>0.062075</td>\n",
       "      <td>0.099221</td>\n",
       "      <td>-0.105478</td>\n",
       "      <td>0.201745</td>\n",
       "      <td>0.326353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Barrier</td>\n",
       "      <td>0.174840</td>\n",
       "      <td>0.176455</td>\n",
       "      <td>0.176455</td>\n",
       "      <td>-0.169017</td>\n",
       "      <td>-0.169017</td>\n",
       "      <td>0.014073</td>\n",
       "      <td>0.014079</td>\n",
       "      <td>1.185514e-01</td>\n",
       "      <td>0.147488</td>\n",
       "      <td>0.202652</td>\n",
       "      <td>0.148861</td>\n",
       "      <td>0.204048</td>\n",
       "      <td>-0.401374</td>\n",
       "      <td>0.063340</td>\n",
       "      <td>0.267929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Gender</td>\n",
       "      <td>0.190835</td>\n",
       "      <td>0.189146</td>\n",
       "      <td>0.189146</td>\n",
       "      <td>0.531791</td>\n",
       "      <td>0.531791</td>\n",
       "      <td>0.021749</td>\n",
       "      <td>0.021762</td>\n",
       "      <td>1.429248e-01</td>\n",
       "      <td>0.147772</td>\n",
       "      <td>0.233028</td>\n",
       "      <td>0.146493</td>\n",
       "      <td>0.231800</td>\n",
       "      <td>0.251663</td>\n",
       "      <td>0.811918</td>\n",
       "      <td>0.261184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>0.087912</td>\n",
       "      <td>0.088692</td>\n",
       "      <td>0.088692</td>\n",
       "      <td>-0.166722</td>\n",
       "      <td>-0.166722</td>\n",
       "      <td>0.022821</td>\n",
       "      <td>0.022827</td>\n",
       "      <td>1.718222e-01</td>\n",
       "      <td>0.043198</td>\n",
       "      <td>0.132654</td>\n",
       "      <td>0.043952</td>\n",
       "      <td>0.133432</td>\n",
       "      <td>-0.503487</td>\n",
       "      <td>0.170043</td>\n",
       "      <td>0.241193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Social Status</td>\n",
       "      <td>0.312480</td>\n",
       "      <td>0.308567</td>\n",
       "      <td>0.308567</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.060488</td>\n",
       "      <td>0.060390</td>\n",
       "      <td>6.514183e-16</td>\n",
       "      <td>0.191630</td>\n",
       "      <td>0.428739</td>\n",
       "      <td>0.190206</td>\n",
       "      <td>0.426928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.232572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>CrossingSignal</td>\n",
       "      <td>0.325109</td>\n",
       "      <td>0.325673</td>\n",
       "      <td>0.325673</td>\n",
       "      <td>0.468531</td>\n",
       "      <td>0.468531</td>\n",
       "      <td>0.016412</td>\n",
       "      <td>0.016413</td>\n",
       "      <td>1.254553e-01</td>\n",
       "      <td>0.292956</td>\n",
       "      <td>0.357290</td>\n",
       "      <td>0.293503</td>\n",
       "      <td>0.357842</td>\n",
       "      <td>0.222644</td>\n",
       "      <td>0.714419</td>\n",
       "      <td>0.194138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.478747</td>\n",
       "      <td>0.478634</td>\n",
       "      <td>0.478634</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>0.063856</td>\n",
       "      <td>0.019489</td>\n",
       "      <td>0.019487</td>\n",
       "      <td>2.267698e-01</td>\n",
       "      <td>0.440539</td>\n",
       "      <td>0.516934</td>\n",
       "      <td>0.440440</td>\n",
       "      <td>0.516827</td>\n",
       "      <td>-0.380605</td>\n",
       "      <td>0.508316</td>\n",
       "      <td>0.133480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.639361</td>\n",
       "      <td>0.639361</td>\n",
       "      <td>0.639361</td>\n",
       "      <td>0.913252</td>\n",
       "      <td>0.913252</td>\n",
       "      <td>0.017907</td>\n",
       "      <td>0.017904</td>\n",
       "      <td>6.095381e-02</td>\n",
       "      <td>0.604264</td>\n",
       "      <td>0.674459</td>\n",
       "      <td>0.604270</td>\n",
       "      <td>0.674453</td>\n",
       "      <td>0.793785</td>\n",
       "      <td>1.032719</td>\n",
       "      <td>0.070262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>0.584435</td>\n",
       "      <td>0.584300</td>\n",
       "      <td>0.584300</td>\n",
       "      <td>0.893877</td>\n",
       "      <td>0.893877</td>\n",
       "      <td>0.017875</td>\n",
       "      <td>0.017876</td>\n",
       "      <td>7.720557e-02</td>\n",
       "      <td>0.549378</td>\n",
       "      <td>0.619447</td>\n",
       "      <td>0.549264</td>\n",
       "      <td>0.619335</td>\n",
       "      <td>0.742557</td>\n",
       "      <td>1.045197</td>\n",
       "      <td>0.070030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.070570</td>\n",
       "      <td>0.070634</td>\n",
       "      <td>0.070634</td>\n",
       "      <td>0.072760</td>\n",
       "      <td>0.072760</td>\n",
       "      <td>0.005587</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>4.593858e-02</td>\n",
       "      <td>0.059621</td>\n",
       "      <td>0.081522</td>\n",
       "      <td>0.059675</td>\n",
       "      <td>0.081593</td>\n",
       "      <td>-0.017278</td>\n",
       "      <td>0.162798</td>\n",
       "      <td>0.348803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Barrier</td>\n",
       "      <td>0.165455</td>\n",
       "      <td>0.166153</td>\n",
       "      <td>0.166153</td>\n",
       "      <td>0.346777</td>\n",
       "      <td>0.346777</td>\n",
       "      <td>0.008354</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>6.197339e-02</td>\n",
       "      <td>0.149101</td>\n",
       "      <td>0.181849</td>\n",
       "      <td>0.149764</td>\n",
       "      <td>0.182541</td>\n",
       "      <td>0.225311</td>\n",
       "      <td>0.468242</td>\n",
       "      <td>0.314843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>0.121141</td>\n",
       "      <td>0.121424</td>\n",
       "      <td>0.121424</td>\n",
       "      <td>-0.026672</td>\n",
       "      <td>-0.026672</td>\n",
       "      <td>0.013640</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>9.798213e-02</td>\n",
       "      <td>0.094404</td>\n",
       "      <td>0.147871</td>\n",
       "      <td>0.094671</td>\n",
       "      <td>0.148177</td>\n",
       "      <td>-0.218713</td>\n",
       "      <td>0.165369</td>\n",
       "      <td>0.302688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>CrossingSignal</td>\n",
       "      <td>0.337387</td>\n",
       "      <td>0.337118</td>\n",
       "      <td>0.337118</td>\n",
       "      <td>0.722096</td>\n",
       "      <td>0.722096</td>\n",
       "      <td>0.009559</td>\n",
       "      <td>0.009565</td>\n",
       "      <td>5.674268e-02</td>\n",
       "      <td>0.318650</td>\n",
       "      <td>0.356121</td>\n",
       "      <td>0.318371</td>\n",
       "      <td>0.355864</td>\n",
       "      <td>0.610882</td>\n",
       "      <td>0.833309</td>\n",
       "      <td>0.276990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Gender</td>\n",
       "      <td>0.160816</td>\n",
       "      <td>0.160137</td>\n",
       "      <td>0.160137</td>\n",
       "      <td>0.426181</td>\n",
       "      <td>0.426181</td>\n",
       "      <td>0.012778</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>9.661790e-02</td>\n",
       "      <td>0.135685</td>\n",
       "      <td>0.185776</td>\n",
       "      <td>0.135080</td>\n",
       "      <td>0.185195</td>\n",
       "      <td>0.236814</td>\n",
       "      <td>0.615549</td>\n",
       "      <td>0.272163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.480450</td>\n",
       "      <td>0.480704</td>\n",
       "      <td>0.480704</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>0.022634</td>\n",
       "      <td>0.011780</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>1.109820e-01</td>\n",
       "      <td>0.457335</td>\n",
       "      <td>0.503510</td>\n",
       "      <td>0.457613</td>\n",
       "      <td>0.503795</td>\n",
       "      <td>-0.194887</td>\n",
       "      <td>0.240155</td>\n",
       "      <td>0.209698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>0.576144</td>\n",
       "      <td>0.575814</td>\n",
       "      <td>0.575814</td>\n",
       "      <td>0.649197</td>\n",
       "      <td>0.649197</td>\n",
       "      <td>0.010745</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>7.825877e-02</td>\n",
       "      <td>0.555035</td>\n",
       "      <td>0.597153</td>\n",
       "      <td>0.554750</td>\n",
       "      <td>0.596878</td>\n",
       "      <td>0.495813</td>\n",
       "      <td>0.802582</td>\n",
       "      <td>0.197574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Social Status</td>\n",
       "      <td>0.177778</td>\n",
       "      <td>0.177513</td>\n",
       "      <td>0.177513</td>\n",
       "      <td>0.209744</td>\n",
       "      <td>0.209744</td>\n",
       "      <td>0.037160</td>\n",
       "      <td>0.037148</td>\n",
       "      <td>2.253594e-01</td>\n",
       "      <td>0.104958</td>\n",
       "      <td>0.250621</td>\n",
       "      <td>0.104704</td>\n",
       "      <td>0.250322</td>\n",
       "      <td>-0.231952</td>\n",
       "      <td>0.651440</td>\n",
       "      <td>0.152533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.649075</td>\n",
       "      <td>0.649047</td>\n",
       "      <td>0.649047</td>\n",
       "      <td>0.861366</td>\n",
       "      <td>0.861366</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>5.011032e-02</td>\n",
       "      <td>0.629304</td>\n",
       "      <td>0.668841</td>\n",
       "      <td>0.629282</td>\n",
       "      <td>0.668812</td>\n",
       "      <td>0.763151</td>\n",
       "      <td>0.959580</td>\n",
       "      <td>0.053008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>gpt4o_wp_Saved_1</td>\n",
       "      <td>Gender</td>\n",
       "      <td>0.159820</td>\n",
       "      <td>0.160006</td>\n",
       "      <td>0.160006</td>\n",
       "      <td>0.073361</td>\n",
       "      <td>0.073361</td>\n",
       "      <td>0.012780</td>\n",
       "      <td>0.012786</td>\n",
       "      <td>1.141160e-01</td>\n",
       "      <td>0.134786</td>\n",
       "      <td>0.184882</td>\n",
       "      <td>0.134946</td>\n",
       "      <td>0.185067</td>\n",
       "      <td>-0.150302</td>\n",
       "      <td>0.297024</td>\n",
       "      <td>0.291664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gpt4o_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.070381</td>\n",
       "      <td>0.070667</td>\n",
       "      <td>0.070667</td>\n",
       "      <td>0.047599</td>\n",
       "      <td>0.047599</td>\n",
       "      <td>0.005589</td>\n",
       "      <td>0.005592</td>\n",
       "      <td>4.541997e-02</td>\n",
       "      <td>0.059436</td>\n",
       "      <td>0.081346</td>\n",
       "      <td>0.059708</td>\n",
       "      <td>0.081627</td>\n",
       "      <td>-0.041423</td>\n",
       "      <td>0.136620</td>\n",
       "      <td>0.275489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>gpt4o_wp_Saved_1</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>0.121355</td>\n",
       "      <td>0.121424</td>\n",
       "      <td>0.121424</td>\n",
       "      <td>0.089476</td>\n",
       "      <td>0.089476</td>\n",
       "      <td>0.013642</td>\n",
       "      <td>0.013650</td>\n",
       "      <td>9.864524e-02</td>\n",
       "      <td>0.094619</td>\n",
       "      <td>0.148096</td>\n",
       "      <td>0.094671</td>\n",
       "      <td>0.148177</td>\n",
       "      <td>-0.103866</td>\n",
       "      <td>0.282817</td>\n",
       "      <td>0.266528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>gpt4o_wp_Saved_1</td>\n",
       "      <td>Social Status</td>\n",
       "      <td>0.179259</td>\n",
       "      <td>0.177513</td>\n",
       "      <td>0.177513</td>\n",
       "      <td>0.385940</td>\n",
       "      <td>0.385940</td>\n",
       "      <td>0.037150</td>\n",
       "      <td>0.037148</td>\n",
       "      <td>2.200157e-01</td>\n",
       "      <td>0.106008</td>\n",
       "      <td>0.251635</td>\n",
       "      <td>0.104704</td>\n",
       "      <td>0.250322</td>\n",
       "      <td>-0.045282</td>\n",
       "      <td>0.817163</td>\n",
       "      <td>0.227492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gpt4o_wp_Saved_1</td>\n",
       "      <td>Barrier</td>\n",
       "      <td>0.165587</td>\n",
       "      <td>0.166153</td>\n",
       "      <td>0.166153</td>\n",
       "      <td>0.440712</td>\n",
       "      <td>0.440712</td>\n",
       "      <td>0.008357</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>5.969115e-02</td>\n",
       "      <td>0.149240</td>\n",
       "      <td>0.182000</td>\n",
       "      <td>0.149764</td>\n",
       "      <td>0.182541</td>\n",
       "      <td>0.323720</td>\n",
       "      <td>0.557705</td>\n",
       "      <td>0.225076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>gpt4o_wp_Saved_1</td>\n",
       "      <td>CrossingSignal</td>\n",
       "      <td>0.337479</td>\n",
       "      <td>0.337118</td>\n",
       "      <td>0.337118</td>\n",
       "      <td>0.763098</td>\n",
       "      <td>0.763098</td>\n",
       "      <td>0.009562</td>\n",
       "      <td>0.009565</td>\n",
       "      <td>5.689188e-02</td>\n",
       "      <td>0.318732</td>\n",
       "      <td>0.356213</td>\n",
       "      <td>0.318371</td>\n",
       "      <td>0.355864</td>\n",
       "      <td>0.651592</td>\n",
       "      <td>0.874604</td>\n",
       "      <td>0.206549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>gpt4o_wp_Saved_1</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>0.575913</td>\n",
       "      <td>0.575750</td>\n",
       "      <td>0.575750</td>\n",
       "      <td>0.449874</td>\n",
       "      <td>0.449874</td>\n",
       "      <td>0.010746</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>9.009709e-02</td>\n",
       "      <td>0.554838</td>\n",
       "      <td>0.596961</td>\n",
       "      <td>0.554683</td>\n",
       "      <td>0.596816</td>\n",
       "      <td>0.273287</td>\n",
       "      <td>0.626461</td>\n",
       "      <td>0.200518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>gpt4o_wp_Saved_1</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.480533</td>\n",
       "      <td>0.480621</td>\n",
       "      <td>0.480621</td>\n",
       "      <td>0.054940</td>\n",
       "      <td>0.054940</td>\n",
       "      <td>0.011782</td>\n",
       "      <td>0.011783</td>\n",
       "      <td>1.112830e-01</td>\n",
       "      <td>0.457441</td>\n",
       "      <td>0.503625</td>\n",
       "      <td>0.457527</td>\n",
       "      <td>0.503716</td>\n",
       "      <td>-0.163171</td>\n",
       "      <td>0.273051</td>\n",
       "      <td>0.197822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>gpt4o_wp_Saved_1</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.649019</td>\n",
       "      <td>0.649047</td>\n",
       "      <td>0.649047</td>\n",
       "      <td>0.372971</td>\n",
       "      <td>0.372971</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>9.358529e-02</td>\n",
       "      <td>0.629238</td>\n",
       "      <td>0.668775</td>\n",
       "      <td>0.629282</td>\n",
       "      <td>0.668812</td>\n",
       "      <td>0.189547</td>\n",
       "      <td>0.556395</td>\n",
       "      <td>0.017036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Utilitarian</td>\n",
       "      <td>0.575637</td>\n",
       "      <td>0.575814</td>\n",
       "      <td>0.575814</td>\n",
       "      <td>0.197025</td>\n",
       "      <td>0.197025</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>0.010747</td>\n",
       "      <td>1.047408e-01</td>\n",
       "      <td>0.554583</td>\n",
       "      <td>0.596709</td>\n",
       "      <td>0.554750</td>\n",
       "      <td>0.596878</td>\n",
       "      <td>-0.008264</td>\n",
       "      <td>0.402313</td>\n",
       "      <td>0.144924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.070607</td>\n",
       "      <td>0.070595</td>\n",
       "      <td>0.070595</td>\n",
       "      <td>0.053665</td>\n",
       "      <td>0.053665</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>0.005591</td>\n",
       "      <td>4.613400e-02</td>\n",
       "      <td>0.059647</td>\n",
       "      <td>0.081566</td>\n",
       "      <td>0.059636</td>\n",
       "      <td>0.081554</td>\n",
       "      <td>-0.036756</td>\n",
       "      <td>0.144086</td>\n",
       "      <td>0.127298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Gender</td>\n",
       "      <td>0.159942</td>\n",
       "      <td>0.160137</td>\n",
       "      <td>0.160137</td>\n",
       "      <td>-0.031501</td>\n",
       "      <td>-0.031501</td>\n",
       "      <td>0.012783</td>\n",
       "      <td>0.012785</td>\n",
       "      <td>1.151309e-01</td>\n",
       "      <td>0.134890</td>\n",
       "      <td>0.184998</td>\n",
       "      <td>0.135080</td>\n",
       "      <td>0.185195</td>\n",
       "      <td>-0.257153</td>\n",
       "      <td>0.194151</td>\n",
       "      <td>0.122063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Barrier</td>\n",
       "      <td>0.165985</td>\n",
       "      <td>0.166191</td>\n",
       "      <td>0.166191</td>\n",
       "      <td>0.199197</td>\n",
       "      <td>0.199197</td>\n",
       "      <td>0.008359</td>\n",
       "      <td>0.008362</td>\n",
       "      <td>6.686318e-02</td>\n",
       "      <td>0.149626</td>\n",
       "      <td>0.182394</td>\n",
       "      <td>0.149802</td>\n",
       "      <td>0.182579</td>\n",
       "      <td>0.068147</td>\n",
       "      <td>0.330246</td>\n",
       "      <td>0.086954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.480811</td>\n",
       "      <td>0.480704</td>\n",
       "      <td>0.480704</td>\n",
       "      <td>0.039813</td>\n",
       "      <td>0.039813</td>\n",
       "      <td>0.011782</td>\n",
       "      <td>0.011781</td>\n",
       "      <td>1.146263e-01</td>\n",
       "      <td>0.457688</td>\n",
       "      <td>0.503873</td>\n",
       "      <td>0.457613</td>\n",
       "      <td>0.503795</td>\n",
       "      <td>-0.184850</td>\n",
       "      <td>0.264476</td>\n",
       "      <td>0.078464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Social Status</td>\n",
       "      <td>0.177560</td>\n",
       "      <td>0.177513</td>\n",
       "      <td>0.177513</td>\n",
       "      <td>0.074043</td>\n",
       "      <td>0.074043</td>\n",
       "      <td>0.037166</td>\n",
       "      <td>0.037148</td>\n",
       "      <td>2.436502e-01</td>\n",
       "      <td>0.104724</td>\n",
       "      <td>0.250412</td>\n",
       "      <td>0.104704</td>\n",
       "      <td>0.250322</td>\n",
       "      <td>-0.403502</td>\n",
       "      <td>0.551589</td>\n",
       "      <td>0.071694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>CrossingSignal</td>\n",
       "      <td>0.337181</td>\n",
       "      <td>0.337118</td>\n",
       "      <td>0.337118</td>\n",
       "      <td>0.193622</td>\n",
       "      <td>0.193622</td>\n",
       "      <td>0.009565</td>\n",
       "      <td>0.009565</td>\n",
       "      <td>8.538197e-02</td>\n",
       "      <td>0.318427</td>\n",
       "      <td>0.355920</td>\n",
       "      <td>0.318371</td>\n",
       "      <td>0.355864</td>\n",
       "      <td>0.026276</td>\n",
       "      <td>0.360967</td>\n",
       "      <td>0.058430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>0.121295</td>\n",
       "      <td>0.121194</td>\n",
       "      <td>0.121194</td>\n",
       "      <td>0.140478</td>\n",
       "      <td>0.140478</td>\n",
       "      <td>0.013653</td>\n",
       "      <td>0.013652</td>\n",
       "      <td>1.020553e-01</td>\n",
       "      <td>0.094487</td>\n",
       "      <td>0.148005</td>\n",
       "      <td>0.094436</td>\n",
       "      <td>0.147951</td>\n",
       "      <td>-0.059547</td>\n",
       "      <td>0.340503</td>\n",
       "      <td>0.058152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.649047</td>\n",
       "      <td>0.649047</td>\n",
       "      <td>0.649047</td>\n",
       "      <td>0.087236</td>\n",
       "      <td>0.087236</td>\n",
       "      <td>0.010086</td>\n",
       "      <td>0.010085</td>\n",
       "      <td>9.759208e-02</td>\n",
       "      <td>0.629259</td>\n",
       "      <td>0.668797</td>\n",
       "      <td>0.629282</td>\n",
       "      <td>0.668812</td>\n",
       "      <td>-0.104041</td>\n",
       "      <td>0.278513</td>\n",
       "      <td>0.024091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            y               x  beta_ppi  beta_hum  \\\n",
       "27          o1mini_wp_Saved_1    Intervention  0.080673  0.080648   \n",
       "28          o1mini_wp_Saved_1         Barrier  0.174840  0.176455   \n",
       "29          o1mini_wp_Saved_1          Gender  0.190835  0.189146   \n",
       "30          o1mini_wp_Saved_1         Fitness  0.087912  0.088692   \n",
       "31          o1mini_wp_Saved_1   Social Status  0.312480  0.308567   \n",
       "32          o1mini_wp_Saved_1  CrossingSignal  0.325109  0.325673   \n",
       "33          o1mini_wp_Saved_1             Age  0.478747  0.478634   \n",
       "35          o1mini_wp_Saved_1         Species  0.639361  0.639361   \n",
       "34          o1mini_wp_Saved_1     Utilitarian  0.584435  0.584300   \n",
       "0        gpt4turbo_wp_Saved_1    Intervention  0.070570  0.070634   \n",
       "1        gpt4turbo_wp_Saved_1         Barrier  0.165455  0.166153   \n",
       "2        gpt4turbo_wp_Saved_1         Fitness  0.121141  0.121424   \n",
       "3        gpt4turbo_wp_Saved_1  CrossingSignal  0.337387  0.337118   \n",
       "4        gpt4turbo_wp_Saved_1          Gender  0.160816  0.160137   \n",
       "5        gpt4turbo_wp_Saved_1             Age  0.480450  0.480704   \n",
       "6        gpt4turbo_wp_Saved_1     Utilitarian  0.576144  0.575814   \n",
       "7        gpt4turbo_wp_Saved_1   Social Status  0.177778  0.177513   \n",
       "8        gpt4turbo_wp_Saved_1         Species  0.649075  0.649047   \n",
       "9            gpt4o_wp_Saved_1          Gender  0.159820  0.160006   \n",
       "10           gpt4o_wp_Saved_1    Intervention  0.070381  0.070667   \n",
       "11           gpt4o_wp_Saved_1         Fitness  0.121355  0.121424   \n",
       "12           gpt4o_wp_Saved_1   Social Status  0.179259  0.177513   \n",
       "13           gpt4o_wp_Saved_1         Barrier  0.165587  0.166153   \n",
       "14           gpt4o_wp_Saved_1  CrossingSignal  0.337479  0.337118   \n",
       "15           gpt4o_wp_Saved_1     Utilitarian  0.575913  0.575750   \n",
       "16           gpt4o_wp_Saved_1             Age  0.480533  0.480621   \n",
       "17           gpt4o_wp_Saved_1         Species  0.649019  0.649047   \n",
       "18  gpt35turbo0125_wp_Saved_1     Utilitarian  0.575637  0.575814   \n",
       "19  gpt35turbo0125_wp_Saved_1    Intervention  0.070607  0.070595   \n",
       "20  gpt35turbo0125_wp_Saved_1          Gender  0.159942  0.160137   \n",
       "21  gpt35turbo0125_wp_Saved_1         Barrier  0.165985  0.166191   \n",
       "22  gpt35turbo0125_wp_Saved_1             Age  0.480811  0.480704   \n",
       "23  gpt35turbo0125_wp_Saved_1   Social Status  0.177560  0.177513   \n",
       "24  gpt35turbo0125_wp_Saved_1  CrossingSignal  0.337181  0.337118   \n",
       "25  gpt35turbo0125_wp_Saved_1         Fitness  0.121295  0.121194   \n",
       "26  gpt35turbo0125_wp_Saved_1         Species  0.649047  0.649047   \n",
       "\n",
       "    beta_hum_sm  beta_sil  beta_sil_sm    se_ppi    se_hum        se_sil  \\\n",
       "27     0.080648  0.048134     0.048134  0.009471  0.009476  7.837482e-02   \n",
       "28     0.176455 -0.169017    -0.169017  0.014073  0.014079  1.185514e-01   \n",
       "29     0.189146  0.531791     0.531791  0.021749  0.021762  1.429248e-01   \n",
       "30     0.088692 -0.166722    -0.166722  0.022821  0.022827  1.718222e-01   \n",
       "31     0.308567  1.000000     1.000000  0.060488  0.060390  6.514183e-16   \n",
       "32     0.325673  0.468531     0.468531  0.016412  0.016413  1.254553e-01   \n",
       "33     0.478634  0.063856     0.063856  0.019489  0.019487  2.267698e-01   \n",
       "35     0.639361  0.913252     0.913252  0.017907  0.017904  6.095381e-02   \n",
       "34     0.584300  0.893877     0.893877  0.017875  0.017876  7.720557e-02   \n",
       "0      0.070634  0.072760     0.072760  0.005587  0.005591  4.593858e-02   \n",
       "1      0.166153  0.346777     0.346777  0.008354  0.008362  6.197339e-02   \n",
       "2      0.121424 -0.026672    -0.026672  0.013640  0.013650  9.798213e-02   \n",
       "3      0.337118  0.722096     0.722096  0.009559  0.009565  5.674268e-02   \n",
       "4      0.160137  0.426181     0.426181  0.012778  0.012785  9.661790e-02   \n",
       "5      0.480704  0.022634     0.022634  0.011780  0.011781  1.109820e-01   \n",
       "6      0.575814  0.649197     0.649197  0.010745  0.010747  7.825877e-02   \n",
       "7      0.177513  0.209744     0.209744  0.037160  0.037148  2.253594e-01   \n",
       "8      0.649047  0.861366     0.861366  0.010086  0.010085  5.011032e-02   \n",
       "9      0.160006  0.073361     0.073361  0.012780  0.012786  1.141160e-01   \n",
       "10     0.070667  0.047599     0.047599  0.005589  0.005592  4.541997e-02   \n",
       "11     0.121424  0.089476     0.089476  0.013642  0.013650  9.864524e-02   \n",
       "12     0.177513  0.385940     0.385940  0.037150  0.037148  2.200157e-01   \n",
       "13     0.166153  0.440712     0.440712  0.008357  0.008362  5.969115e-02   \n",
       "14     0.337118  0.763098     0.763098  0.009562  0.009565  5.689188e-02   \n",
       "15     0.575750  0.449874     0.449874  0.010746  0.010749  9.009709e-02   \n",
       "16     0.480621  0.054940     0.054940  0.011782  0.011783  1.112830e-01   \n",
       "17     0.649047  0.372971     0.372971  0.010086  0.010085  9.358529e-02   \n",
       "18     0.575814  0.197025     0.197025  0.010747  0.010747  1.047408e-01   \n",
       "19     0.070595  0.053665     0.053665  0.005591  0.005591  4.613400e-02   \n",
       "20     0.160137 -0.031501    -0.031501  0.012783  0.012785  1.151309e-01   \n",
       "21     0.166191  0.199197     0.199197  0.008359  0.008362  6.686318e-02   \n",
       "22     0.480704  0.039813     0.039813  0.011782  0.011781  1.146263e-01   \n",
       "23     0.177513  0.074043     0.074043  0.037166  0.037148  2.436502e-01   \n",
       "24     0.337118  0.193622     0.193622  0.009565  0.009565  8.538197e-02   \n",
       "25     0.121194  0.140478     0.140478  0.013653  0.013652  1.020553e-01   \n",
       "26     0.649047  0.087236     0.087236  0.010086  0.010085  9.759208e-02   \n",
       "\n",
       "    lower_ppi  upper_ppi  lower_hum  upper_hum  lower_sil  upper_sil  ppi_corr  \n",
       "27   0.062109   0.099235   0.062075   0.099221  -0.105478   0.201745  0.326353  \n",
       "28   0.147488   0.202652   0.148861   0.204048  -0.401374   0.063340  0.267929  \n",
       "29   0.147772   0.233028   0.146493   0.231800   0.251663   0.811918  0.261184  \n",
       "30   0.043198   0.132654   0.043952   0.133432  -0.503487   0.170043  0.241193  \n",
       "31   0.191630   0.428739   0.190206   0.426928   1.000000   1.000000  0.232572  \n",
       "32   0.292956   0.357290   0.293503   0.357842   0.222644   0.714419  0.194138  \n",
       "33   0.440539   0.516934   0.440440   0.516827  -0.380605   0.508316  0.133480  \n",
       "35   0.604264   0.674459   0.604270   0.674453   0.793785   1.032719  0.070262  \n",
       "34   0.549378   0.619447   0.549264   0.619335   0.742557   1.045197  0.070030  \n",
       "0    0.059621   0.081522   0.059675   0.081593  -0.017278   0.162798  0.348803  \n",
       "1    0.149101   0.181849   0.149764   0.182541   0.225311   0.468242  0.314843  \n",
       "2    0.094404   0.147871   0.094671   0.148177  -0.218713   0.165369  0.302688  \n",
       "3    0.318650   0.356121   0.318371   0.355864   0.610882   0.833309  0.276990  \n",
       "4    0.135685   0.185776   0.135080   0.185195   0.236814   0.615549  0.272163  \n",
       "5    0.457335   0.503510   0.457613   0.503795  -0.194887   0.240155  0.209698  \n",
       "6    0.555035   0.597153   0.554750   0.596878   0.495813   0.802582  0.197574  \n",
       "7    0.104958   0.250621   0.104704   0.250322  -0.231952   0.651440  0.152533  \n",
       "8    0.629304   0.668841   0.629282   0.668812   0.763151   0.959580  0.053008  \n",
       "9    0.134786   0.184882   0.134946   0.185067  -0.150302   0.297024  0.291664  \n",
       "10   0.059436   0.081346   0.059708   0.081627  -0.041423   0.136620  0.275489  \n",
       "11   0.094619   0.148096   0.094671   0.148177  -0.103866   0.282817  0.266528  \n",
       "12   0.106008   0.251635   0.104704   0.250322  -0.045282   0.817163  0.227492  \n",
       "13   0.149240   0.182000   0.149764   0.182541   0.323720   0.557705  0.225076  \n",
       "14   0.318732   0.356213   0.318371   0.355864   0.651592   0.874604  0.206549  \n",
       "15   0.554838   0.596961   0.554683   0.596816   0.273287   0.626461  0.200518  \n",
       "16   0.457441   0.503625   0.457527   0.503716  -0.163171   0.273051  0.197822  \n",
       "17   0.629238   0.668775   0.629282   0.668812   0.189547   0.556395  0.017036  \n",
       "18   0.554583   0.596709   0.554750   0.596878  -0.008264   0.402313  0.144924  \n",
       "19   0.059647   0.081566   0.059636   0.081554  -0.036756   0.144086  0.127298  \n",
       "20   0.134890   0.184998   0.135080   0.185195  -0.257153   0.194151  0.122063  \n",
       "21   0.149626   0.182394   0.149802   0.182579   0.068147   0.330246  0.086954  \n",
       "22   0.457688   0.503873   0.457613   0.503795  -0.184850   0.264476  0.078464  \n",
       "23   0.104724   0.250412   0.104704   0.250322  -0.403502   0.551589  0.071694  \n",
       "24   0.318427   0.355920   0.318371   0.355864   0.026276   0.360967  0.058430  \n",
       "25   0.094487   0.148005   0.094436   0.147951  -0.059547   0.340503  0.058152  \n",
       "26   0.629259   0.668797   0.629282   0.668812  -0.104041   0.278513  0.024091  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = df[\"ResponseID\"].unique()\n",
    "n = 22000\n",
    "N = len(ids) - n\n",
    "random.seed(2024)\n",
    "\n",
    "n_ids = random.sample(ids.tolist(), k=n)\n",
    "N_ids = random.sample(list(set(ids) - set(n_ids)), k=N)\n",
    "\n",
    "df_human = df[ df[\"ResponseID\"].isin(n_ids) ]\n",
    "df_silicon = df [ df[\"ResponseID\"].isin(N_ids)]\n",
    "\n",
    "models = [\n",
    "    \"gpt4turbo_wp_Saved_1\",\"gpt4o_wp_Saved_1\",\"gpt35turbo0125_wp_Saved_1\",\n",
    "    \"o1mini_wp_Saved_1\",#\"claude-3-5-sonnet-20241022_wp_Saved_1\"\n",
    "]\n",
    "\n",
    "results2 = pd.DataFrame()\n",
    "for model in models: \n",
    "    \n",
    "    print(\"Model: \", model)\n",
    "    results1 = pd.concat([\n",
    "        compute_amce_ppi(df_human, df_silicon, x=\"Intervention\", y=model), \n",
    "        compute_amce_ppi(df_human, df_silicon, x=\"Barrier\", y=model), \n",
    "        compute_amce_ppi(df_human, df_silicon, x=\"Gender\", y=model), \n",
    "        compute_amce_ppi(df_human, df_silicon, x=\"Fitness\", y=model), \n",
    "        compute_amce_ppi(df_human, df_silicon, x=\"Social Status\", y=model), \n",
    "        compute_amce_ppi(df_human, df_silicon, x=\"CrossingSignal\",y=model),\n",
    "        compute_amce_ppi(df_human, df_silicon, x=\"Age\", y=model),\n",
    "        compute_amce_ppi(df_human, df_silicon, x=\"Utilitarian\", y=model),\n",
    "        compute_amce_ppi(df_human, df_silicon, x=\"Species\", y=model)\n",
    "    ],ignore_index=True)\n",
    "    \n",
    "    results2 = pd.concat([results2, results1],ignore_index=True).sort_values(by=[\"y\",\"ppi_corr\"], ascending=False)\n",
    "    \n",
    "results2.to_csv(\"../Data/7_rho.csv\", index=False)\n",
    "results2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we vary the number of human subjects and silicon subjects in a simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iterating predictions from the model: gpt4turbo_wp_Saved_1\n",
      "    Predictor: Intervention\n",
      "        Human sample size: 500\n",
      "    Predictor: Barrier\n",
      "        Human sample size: 500\n",
      "    Predictor: CrossingSignal\n",
      "        Human sample size: 500\n",
      "    Predictor: Gender\n",
      "        Human sample size: 500\n",
      "    Predictor: Fitness\n",
      "        Human sample size: 500\n",
      "    Predictor: Social Status\n",
      "        Human sample size: 500\n",
      "    Predictor: Age\n",
      "        Human sample size: 500\n",
      "    Predictor: Utilitarian\n",
      "        Human sample size: 500\n"
     ]
    }
   ],
   "source": [
    "# sample size of human subjects\n",
    "ns = [500,750]\n",
    "ns= [500]\n",
    "\n",
    "# multiples of human subjects sample size\n",
    "ks = list([0.1, 0.25, 0.5, 0.75]) + list(np.arange(1, 10.5, 0.5))\n",
    "\n",
    "# number of repetitions for combinations of n and N\n",
    "reps = 50\n",
    "\n",
    "# LLM predictions\n",
    "Ys = models\n",
    "Ys = [\"gpt4turbo_wp_Saved_1\"]\n",
    "\n",
    "# structural attributes of scenarios\n",
    "Xs_structural  = ['Intervention', 'Barrier','CrossingSignal']\n",
    "\n",
    "# attributes of characters\n",
    "Xs_characters = ['Gender','Fitness','Social Status','Age','Utilitarian','Species']\n",
    "\n",
    "# all attributes\n",
    "Xs = Xs_structural + Xs_characters\n",
    "\n",
    "result = pd.DataFrame()\n",
    "\n",
    "# loop models\n",
    "for y in Ys:\n",
    "  \n",
    "  print(f\"Iterating predictions from the model: {y}\")\n",
    "  \n",
    "  # loop over predictors\n",
    "  for x in Xs:\n",
    "    print(f\"    Predictor: {x}\")\n",
    "\n",
    "    # loop over sample sizes of human subjects\n",
    "    for n in ns:\n",
    "      print(f\"        Human sample size: {n}\")\n",
    "\n",
    "      # sample size silicon subjects \n",
    "      Ns = [int(n * k) for n in ns for k in ks]\n",
    "      \n",
    "      # loop over sample sizes of silicon subjects\n",
    "      for N in Ns:\n",
    "        \n",
    "        # loop over repetitions\n",
    "        for r in range(reps):\n",
    "\n",
    "          # subset to dilemmas with variation on structural attribute\n",
    "          if x in Xs_structural:\n",
    "\n",
    "              cnt = df.groupby(\"ResponseID\")[x].nunique()\n",
    "              ids = cnt[ cnt > 1].index.tolist()\n",
    "\n",
    "          # subset to dilemmas with relevant character attribute\n",
    "          if x in Xs_characters:\n",
    "\n",
    "              ids = df.loc[ (df[\"ScenarioType\"]==x) & (df[\"ScenarioTypeStrict\"]==x), \"ResponseID\"].tolist()\n",
    "          \n",
    "          # skip current iteration if target n is larger than population\n",
    "          if (len(ids) < n):\n",
    "             continue \n",
    "\n",
    "          # sample dilemmas for human subjects sample\n",
    "          n_ids = random.sample(ids, k=n)\n",
    "          \n",
    "          # get remaining dilemma ids to sample from\n",
    "          remaining_ids = list(set(ids) - set(n_ids))\n",
    "\n",
    "          # skip current iteration if target N is larger than population\n",
    "          if (len(remaining_ids) < N):\n",
    "             continue \n",
    "          \n",
    "          # sample dilemmas for silicon subjects sample\n",
    "          N_ids = random.sample(remaining_ids, k=N)\n",
    "\n",
    "          # subset data\n",
    "          df_human = df[ df[\"ResponseID\"].isin(n_ids) ]\n",
    "          df_silicon = df [ df[\"ResponseID\"].isin(N_ids)]\n",
    "\n",
    "          # compute acme on n human subjects and N silicon subjects\n",
    "          ppi = compute_amce_ppi(n_data=df_human, N_data=df_silicon, x=x, y=y)\n",
    "\n",
    "          # store data\n",
    "          ppi[\"n\"] = n\n",
    "          ppi[\"N\"] = N\n",
    "          \n",
    "          result = pd.concat([result, ppi], ignore_index=True)\n",
    "          \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We benchmark the silicon subjects design and the mixed subjects design against a human subjects approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>beta_ppi</th>\n",
       "      <th>beta_hum</th>\n",
       "      <th>beta_hum_sm</th>\n",
       "      <th>beta_sil</th>\n",
       "      <th>beta_sil_sm</th>\n",
       "      <th>se_ppi</th>\n",
       "      <th>se_hum</th>\n",
       "      <th>se_sil</th>\n",
       "      <th>...</th>\n",
       "      <th>upper_hum</th>\n",
       "      <th>lower_sil</th>\n",
       "      <th>upper_sil</th>\n",
       "      <th>ppi_corr</th>\n",
       "      <th>n</th>\n",
       "      <th>N</th>\n",
       "      <th>param</th>\n",
       "      <th>coverage_ppi</th>\n",
       "      <th>coverage_sil</th>\n",
       "      <th>coverage_hum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.030414</td>\n",
       "      <td>0.040908</td>\n",
       "      <td>0.040908</td>\n",
       "      <td>-0.128529</td>\n",
       "      <td>-0.128529</td>\n",
       "      <td>0.036530</td>\n",
       "      <td>0.036902</td>\n",
       "      <td>0.110550</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113234</td>\n",
       "      <td>-0.345203</td>\n",
       "      <td>0.088145</td>\n",
       "      <td>0.449060</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.065392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.056072</td>\n",
       "      <td>0.053008</td>\n",
       "      <td>0.053008</td>\n",
       "      <td>0.090701</td>\n",
       "      <td>0.090701</td>\n",
       "      <td>0.036729</td>\n",
       "      <td>0.036950</td>\n",
       "      <td>0.110108</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125428</td>\n",
       "      <td>-0.125108</td>\n",
       "      <td>0.306509</td>\n",
       "      <td>0.342804</td>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>0.065392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.031872</td>\n",
       "      <td>0.035247</td>\n",
       "      <td>0.035247</td>\n",
       "      <td>0.089163</td>\n",
       "      <td>0.089163</td>\n",
       "      <td>0.036410</td>\n",
       "      <td>0.037322</td>\n",
       "      <td>0.074596</td>\n",
       "      <td>...</td>\n",
       "      <td>0.108398</td>\n",
       "      <td>-0.057043</td>\n",
       "      <td>0.235369</td>\n",
       "      <td>0.509993</td>\n",
       "      <td>500</td>\n",
       "      <td>125</td>\n",
       "      <td>0.065392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.060632</td>\n",
       "      <td>0.058040</td>\n",
       "      <td>0.058040</td>\n",
       "      <td>0.103081</td>\n",
       "      <td>0.103081</td>\n",
       "      <td>0.037225</td>\n",
       "      <td>0.037554</td>\n",
       "      <td>0.070963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.131644</td>\n",
       "      <td>-0.036003</td>\n",
       "      <td>0.242165</td>\n",
       "      <td>0.285535</td>\n",
       "      <td>500</td>\n",
       "      <td>125</td>\n",
       "      <td>0.065392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.126876</td>\n",
       "      <td>0.134947</td>\n",
       "      <td>0.134947</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.019584</td>\n",
       "      <td>0.036458</td>\n",
       "      <td>0.036883</td>\n",
       "      <td>0.050939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.207237</td>\n",
       "      <td>-0.080254</td>\n",
       "      <td>0.119423</td>\n",
       "      <td>0.278100</td>\n",
       "      <td>500</td>\n",
       "      <td>250</td>\n",
       "      <td>0.065392</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.587258</td>\n",
       "      <td>0.589980</td>\n",
       "      <td>0.589980</td>\n",
       "      <td>0.774952</td>\n",
       "      <td>0.774952</td>\n",
       "      <td>0.058845</td>\n",
       "      <td>0.058742</td>\n",
       "      <td>0.016036</td>\n",
       "      <td>...</td>\n",
       "      <td>0.705112</td>\n",
       "      <td>0.743522</td>\n",
       "      <td>0.806383</td>\n",
       "      <td>0.025349</td>\n",
       "      <td>500</td>\n",
       "      <td>3000</td>\n",
       "      <td>0.632202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.671314</td>\n",
       "      <td>0.681742</td>\n",
       "      <td>0.681742</td>\n",
       "      <td>0.760172</td>\n",
       "      <td>0.760172</td>\n",
       "      <td>0.046196</td>\n",
       "      <td>0.045972</td>\n",
       "      <td>0.016295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.771846</td>\n",
       "      <td>0.728235</td>\n",
       "      <td>0.792110</td>\n",
       "      <td>0.072532</td>\n",
       "      <td>500</td>\n",
       "      <td>3250</td>\n",
       "      <td>0.632202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.540384</td>\n",
       "      <td>0.540384</td>\n",
       "      <td>0.540384</td>\n",
       "      <td>0.800637</td>\n",
       "      <td>0.800637</td>\n",
       "      <td>0.058029</td>\n",
       "      <td>0.057931</td>\n",
       "      <td>0.014835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.653926</td>\n",
       "      <td>0.771560</td>\n",
       "      <td>0.829714</td>\n",
       "      <td>0.196161</td>\n",
       "      <td>500</td>\n",
       "      <td>3250</td>\n",
       "      <td>0.632202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.573510</td>\n",
       "      <td>0.570771</td>\n",
       "      <td>0.570771</td>\n",
       "      <td>0.787262</td>\n",
       "      <td>0.787262</td>\n",
       "      <td>0.050695</td>\n",
       "      <td>0.050752</td>\n",
       "      <td>0.014963</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670243</td>\n",
       "      <td>0.757935</td>\n",
       "      <td>0.816590</td>\n",
       "      <td>0.062043</td>\n",
       "      <td>500</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.632202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1223</th>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Species</td>\n",
       "      <td>0.611653</td>\n",
       "      <td>0.612167</td>\n",
       "      <td>0.612167</td>\n",
       "      <td>0.771891</td>\n",
       "      <td>0.771891</td>\n",
       "      <td>0.052443</td>\n",
       "      <td>0.052366</td>\n",
       "      <td>0.015348</td>\n",
       "      <td>...</td>\n",
       "      <td>0.714803</td>\n",
       "      <td>0.741810</td>\n",
       "      <td>0.801972</td>\n",
       "      <td>0.062304</td>\n",
       "      <td>500</td>\n",
       "      <td>3500</td>\n",
       "      <td>0.632202</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1224 rows  23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         y             x  beta_ppi  beta_hum  beta_hum_sm  \\\n",
       "0     gpt4turbo_wp_Saved_1  Intervention  0.030414  0.040908     0.040908   \n",
       "1     gpt4turbo_wp_Saved_1  Intervention  0.056072  0.053008     0.053008   \n",
       "2     gpt4turbo_wp_Saved_1  Intervention  0.031872  0.035247     0.035247   \n",
       "3     gpt4turbo_wp_Saved_1  Intervention  0.060632  0.058040     0.058040   \n",
       "4     gpt4turbo_wp_Saved_1  Intervention  0.126876  0.134947     0.134947   \n",
       "...                    ...           ...       ...       ...          ...   \n",
       "1219     o1mini_wp_Saved_1       Species  0.587258  0.589980     0.589980   \n",
       "1220     o1mini_wp_Saved_1       Species  0.671314  0.681742     0.681742   \n",
       "1221     o1mini_wp_Saved_1       Species  0.540384  0.540384     0.540384   \n",
       "1222     o1mini_wp_Saved_1       Species  0.573510  0.570771     0.570771   \n",
       "1223     o1mini_wp_Saved_1       Species  0.611653  0.612167     0.612167   \n",
       "\n",
       "      beta_sil  beta_sil_sm    se_ppi    se_hum    se_sil  ...  upper_hum  \\\n",
       "0    -0.128529    -0.128529  0.036530  0.036902  0.110550  ...   0.113234   \n",
       "1     0.090701     0.090701  0.036729  0.036950  0.110108  ...   0.125428   \n",
       "2     0.089163     0.089163  0.036410  0.037322  0.074596  ...   0.108398   \n",
       "3     0.103081     0.103081  0.037225  0.037554  0.070963  ...   0.131644   \n",
       "4     0.019584     0.019584  0.036458  0.036883  0.050939  ...   0.207237   \n",
       "...        ...          ...       ...       ...       ...  ...        ...   \n",
       "1219  0.774952     0.774952  0.058845  0.058742  0.016036  ...   0.705112   \n",
       "1220  0.760172     0.760172  0.046196  0.045972  0.016295  ...   0.771846   \n",
       "1221  0.800637     0.800637  0.058029  0.057931  0.014835  ...   0.653926   \n",
       "1222  0.787262     0.787262  0.050695  0.050752  0.014963  ...   0.670243   \n",
       "1223  0.771891     0.771891  0.052443  0.052366  0.015348  ...   0.714803   \n",
       "\n",
       "      lower_sil  upper_sil  ppi_corr    n     N     param  coverage_ppi  \\\n",
       "0     -0.345203   0.088145  0.449060  500    50  0.065392             1   \n",
       "1     -0.125108   0.306509  0.342804  500    50  0.065392             1   \n",
       "2     -0.057043   0.235369  0.509993  500   125  0.065392             1   \n",
       "3     -0.036003   0.242165  0.285535  500   125  0.065392             1   \n",
       "4     -0.080254   0.119423  0.278100  500   250  0.065392             1   \n",
       "...         ...        ...       ...  ...   ...       ...           ...   \n",
       "1219   0.743522   0.806383  0.025349  500  3000  0.632202             1   \n",
       "1220   0.728235   0.792110  0.072532  500  3250  0.632202             1   \n",
       "1221   0.771560   0.829714  0.196161  500  3250  0.632202             1   \n",
       "1222   0.757935   0.816590  0.062043  500  3500  0.632202             1   \n",
       "1223   0.741810   0.801972  0.062304  500  3500  0.632202             1   \n",
       "\n",
       "      coverage_sil  coverage_hum  \n",
       "0                1             1  \n",
       "1                1             1  \n",
       "2                1             1  \n",
       "3                1             1  \n",
       "4                1             1  \n",
       "...            ...           ...  \n",
       "1219             0             1  \n",
       "1220             0             1  \n",
       "1221             0             1  \n",
       "1222             0             1  \n",
       "1223             0             1  \n",
       "\n",
       "[1224 rows x 23 columns]"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subset point estimates of AMCEs from the entire human subjects sample\n",
    "benchmark = amce_human_subjects.loc[:, ['x', 'beta']].rename(columns={'beta': 'param'})\n",
    "\n",
    "# merge benchmark with results from simulation\n",
    "result_wb = pd.merge(result, benchmark, on='x', how='left')\n",
    "\n",
    "# report if true value is within the confidence interval from the mixed subjects \n",
    "result_wb['coverage_ppi'] = (\n",
    "    (result_wb['lower_ppi'] <= result_wb['param']) & \n",
    "    (result_wb['param'] <= result_wb['upper_ppi'])\n",
    ").astype(int) \n",
    "\n",
    "# report if true value is within the confidence interval from the silicon subjects \n",
    "result_wb['coverage_sil'] = (\n",
    "    (result_wb['lower_sil'] <= result_wb['param']) & \n",
    "    (result_wb['param'] <= result_wb['upper_sil'])\n",
    ").astype(int) \n",
    "\n",
    "# report if true value is within the confidence interval from the silicon subjects \n",
    "result_wb['coverage_hum'] = (\n",
    "    (result_wb['lower_hum'] <= result_wb['param']) & \n",
    "    (result_wb['param'] <= result_wb['upper_hum'])\n",
    ").astype(int) \n",
    "\n",
    "result_wb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>N</th>\n",
       "      <th>y</th>\n",
       "      <th>x</th>\n",
       "      <th>param</th>\n",
       "      <th>beta_ppi</th>\n",
       "      <th>se_ppi</th>\n",
       "      <th>lower_ppi</th>\n",
       "      <th>upper_ppi</th>\n",
       "      <th>coverage_ppi</th>\n",
       "      <th>...</th>\n",
       "      <th>lower_hum</th>\n",
       "      <th>upper_hum</th>\n",
       "      <th>coverage_hum</th>\n",
       "      <th>repetitions</th>\n",
       "      <th>bias_ppi</th>\n",
       "      <th>bias_sil</th>\n",
       "      <th>bias_hum</th>\n",
       "      <th>rmse_ppi</th>\n",
       "      <th>rmse_sil</th>\n",
       "      <th>rmse_hum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Age</td>\n",
       "      <td>0.494434</td>\n",
       "      <td>0.465116</td>\n",
       "      <td>0.033706</td>\n",
       "      <td>0.398940</td>\n",
       "      <td>0.531066</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.399077</td>\n",
       "      <td>0.531258</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.029318</td>\n",
       "      <td>-0.569923</td>\n",
       "      <td>-0.029267</td>\n",
       "      <td>0.044673</td>\n",
       "      <td>0.580647</td>\n",
       "      <td>0.044650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Barrier</td>\n",
       "      <td>0.150271</td>\n",
       "      <td>0.142049</td>\n",
       "      <td>0.040863</td>\n",
       "      <td>0.062077</td>\n",
       "      <td>0.222257</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062300</td>\n",
       "      <td>0.221756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.008221</td>\n",
       "      <td>0.171604</td>\n",
       "      <td>-0.008242</td>\n",
       "      <td>0.041682</td>\n",
       "      <td>0.216308</td>\n",
       "      <td>0.041505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>CrossingSignal</td>\n",
       "      <td>0.339410</td>\n",
       "      <td>0.372408</td>\n",
       "      <td>0.045715</td>\n",
       "      <td>0.282668</td>\n",
       "      <td>0.461868</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.282919</td>\n",
       "      <td>0.461987</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.032997</td>\n",
       "      <td>-0.355134</td>\n",
       "      <td>0.033043</td>\n",
       "      <td>0.056380</td>\n",
       "      <td>0.384300</td>\n",
       "      <td>0.056379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Fitness</td>\n",
       "      <td>0.130361</td>\n",
       "      <td>0.121131</td>\n",
       "      <td>0.037347</td>\n",
       "      <td>0.047971</td>\n",
       "      <td>0.194370</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048335</td>\n",
       "      <td>0.194675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.009230</td>\n",
       "      <td>-0.209160</td>\n",
       "      <td>-0.008857</td>\n",
       "      <td>0.038471</td>\n",
       "      <td>0.239064</td>\n",
       "      <td>0.038369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500</td>\n",
       "      <td>50</td>\n",
       "      <td>gpt35turbo0125_wp_Saved_1</td>\n",
       "      <td>Gender</td>\n",
       "      <td>0.155021</td>\n",
       "      <td>0.148579</td>\n",
       "      <td>0.036964</td>\n",
       "      <td>0.075892</td>\n",
       "      <td>0.220790</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.075235</td>\n",
       "      <td>0.220170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.006442</td>\n",
       "      <td>0.013858</td>\n",
       "      <td>-0.007319</td>\n",
       "      <td>0.037522</td>\n",
       "      <td>0.108909</td>\n",
       "      <td>0.037691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>CrossingSignal</td>\n",
       "      <td>0.339410</td>\n",
       "      <td>0.337888</td>\n",
       "      <td>0.044689</td>\n",
       "      <td>0.250298</td>\n",
       "      <td>0.425475</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247190</td>\n",
       "      <td>0.428821</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001522</td>\n",
       "      <td>0.326841</td>\n",
       "      <td>-0.001405</td>\n",
       "      <td>0.044715</td>\n",
       "      <td>0.327055</td>\n",
       "      <td>0.046357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>gpt4turbo_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.065392</td>\n",
       "      <td>0.066117</td>\n",
       "      <td>0.034977</td>\n",
       "      <td>-0.002530</td>\n",
       "      <td>0.134578</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001432</td>\n",
       "      <td>0.142330</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000726</td>\n",
       "      <td>0.016202</td>\n",
       "      <td>0.005058</td>\n",
       "      <td>0.034985</td>\n",
       "      <td>0.019845</td>\n",
       "      <td>0.037022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>609</th>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Barrier</td>\n",
       "      <td>0.150271</td>\n",
       "      <td>0.153690</td>\n",
       "      <td>0.064509</td>\n",
       "      <td>0.026543</td>\n",
       "      <td>0.279415</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007683</td>\n",
       "      <td>0.264770</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.003419</td>\n",
       "      <td>0.052192</td>\n",
       "      <td>-0.021728</td>\n",
       "      <td>0.064600</td>\n",
       "      <td>0.056618</td>\n",
       "      <td>0.072822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>610</th>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>CrossingSignal</td>\n",
       "      <td>0.339410</td>\n",
       "      <td>0.245460</td>\n",
       "      <td>0.080240</td>\n",
       "      <td>0.088225</td>\n",
       "      <td>0.402760</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096890</td>\n",
       "      <td>0.419873</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.093950</td>\n",
       "      <td>0.277240</td>\n",
       "      <td>-0.081029</td>\n",
       "      <td>0.123552</td>\n",
       "      <td>0.278042</td>\n",
       "      <td>0.115563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>500</td>\n",
       "      <td>5000</td>\n",
       "      <td>o1mini_wp_Saved_1</td>\n",
       "      <td>Intervention</td>\n",
       "      <td>0.065392</td>\n",
       "      <td>0.064336</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>-0.061953</td>\n",
       "      <td>0.179270</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.106083</td>\n",
       "      <td>0.142457</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.001055</td>\n",
       "      <td>-0.004432</td>\n",
       "      <td>-0.047205</td>\n",
       "      <td>0.061547</td>\n",
       "      <td>0.020478</td>\n",
       "      <td>0.079047</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>612 rows  28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       n     N                          y               x     param  beta_ppi  \\\n",
       "0    500    50  gpt35turbo0125_wp_Saved_1             Age  0.494434  0.465116   \n",
       "1    500    50  gpt35turbo0125_wp_Saved_1         Barrier  0.150271  0.142049   \n",
       "2    500    50  gpt35turbo0125_wp_Saved_1  CrossingSignal  0.339410  0.372408   \n",
       "3    500    50  gpt35turbo0125_wp_Saved_1         Fitness  0.130361  0.121131   \n",
       "4    500    50  gpt35turbo0125_wp_Saved_1          Gender  0.155021  0.148579   \n",
       "..   ...   ...                        ...             ...       ...       ...   \n",
       "607  500  5000       gpt4turbo_wp_Saved_1  CrossingSignal  0.339410  0.337888   \n",
       "608  500  5000       gpt4turbo_wp_Saved_1    Intervention  0.065392  0.066117   \n",
       "609  500  5000          o1mini_wp_Saved_1         Barrier  0.150271  0.153690   \n",
       "610  500  5000          o1mini_wp_Saved_1  CrossingSignal  0.339410  0.245460   \n",
       "611  500  5000          o1mini_wp_Saved_1    Intervention  0.065392  0.064336   \n",
       "\n",
       "       se_ppi  lower_ppi  upper_ppi  coverage_ppi  ...  lower_hum  upper_hum  \\\n",
       "0    0.033706   0.398940   0.531066           1.0  ...   0.399077   0.531258   \n",
       "1    0.040863   0.062077   0.222257           1.0  ...   0.062300   0.221756   \n",
       "2    0.045715   0.282668   0.461868           1.0  ...   0.282919   0.461987   \n",
       "3    0.037347   0.047971   0.194370           1.0  ...   0.048335   0.194675   \n",
       "4    0.036964   0.075892   0.220790           1.0  ...   0.075235   0.220170   \n",
       "..        ...        ...        ...           ...  ...        ...        ...   \n",
       "607  0.044689   0.250298   0.425475           1.0  ...   0.247190   0.428821   \n",
       "608  0.034977  -0.002530   0.134578           1.0  ...  -0.001432   0.142330   \n",
       "609  0.064509   0.026543   0.279415           1.0  ...  -0.007683   0.264770   \n",
       "610  0.080240   0.088225   0.402760           1.0  ...   0.096890   0.419873   \n",
       "611  0.061538  -0.061953   0.179270           1.0  ...  -0.106083   0.142457   \n",
       "\n",
       "     coverage_hum  repetitions  bias_ppi  bias_sil  bias_hum  rmse_ppi  \\\n",
       "0             1.0            2 -0.029318 -0.569923 -0.029267  0.044673   \n",
       "1             1.0            2 -0.008221  0.171604 -0.008242  0.041682   \n",
       "2             1.0            2  0.032997 -0.355134  0.033043  0.056380   \n",
       "3             1.0            2 -0.009230 -0.209160 -0.008857  0.038471   \n",
       "4             1.0            2 -0.006442  0.013858 -0.007319  0.037522   \n",
       "..            ...          ...       ...       ...       ...       ...   \n",
       "607           1.0            2 -0.001522  0.326841 -0.001405  0.044715   \n",
       "608           1.0            2  0.000726  0.016202  0.005058  0.034985   \n",
       "609           1.0            2  0.003419  0.052192 -0.021728  0.064600   \n",
       "610           1.0            2 -0.093950  0.277240 -0.081029  0.123552   \n",
       "611           1.0            2 -0.001055 -0.004432 -0.047205  0.061547   \n",
       "\n",
       "     rmse_sil  rmse_hum  \n",
       "0    0.580647  0.044650  \n",
       "1    0.216308  0.041505  \n",
       "2    0.384300  0.056379  \n",
       "3    0.239064  0.038369  \n",
       "4    0.108909  0.037691  \n",
       "..        ...       ...  \n",
       "607  0.327055  0.046357  \n",
       "608  0.019845  0.037022  \n",
       "609  0.056618  0.072822  \n",
       "610  0.278042  0.115563  \n",
       "611  0.020478  0.079047  \n",
       "\n",
       "[612 rows x 28 columns]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by n, N, and LLM then calculate mean across repetitions\n",
    "stats = ['beta_ppi','se_ppi','lower_ppi','upper_ppi','coverage_ppi','ppi_corr',\n",
    "         'beta_sil','se_sil','lower_sil','upper_sil','coverage_sil',\n",
    "         'beta_hum','se_hum','lower_hum','upper_hum','coverage_hum']\n",
    "\n",
    "summ = result_wb.groupby(['n','N','y','x','param'])[stats].mean().reset_index()\n",
    "\n",
    "# Calculate bias columns\n",
    "summ['repetitions'] = reps\n",
    "summ['bias_ppi'] = summ['beta_ppi'] - summ['param']\n",
    "summ['bias_sil'] = summ['beta_sil'] - summ['param']\n",
    "summ['bias_hum'] = summ['beta_hum'] - summ['param']\n",
    "\n",
    "summ['rmse_ppi'] = np.sqrt(summ['bias_ppi']**2 + summ['se_ppi']**2)\n",
    "summ['rmse_sil'] = np.sqrt(summ['bias_sil']**2 + summ['se_sil']**2)\n",
    "summ['rmse_hum'] = np.sqrt(summ['bias_hum']**2 + summ['se_hum']**2)\n",
    "\n",
    "# Save averaged simulation results to compressed csv file\n",
    "summ.to_csv(\"../Data/7_ResultsPPI.csv.gz\", compression=\"gzip\", index=False)\n",
    "summ"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
